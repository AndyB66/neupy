<!DOCTYPE html><!--[if lt IE 7]>      <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js"> <!--<![endif]-->
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <meta name="description" content="NeuPy is a Python library for Artificial Neural Networks. NeuPy supports many different types of Neural Networks from a simple perceptron to deep learning models.">
        <meta name="viewport" content="width=device-width">
        <title>Basics &mdash; NeuPy</title>
            <link rel="stylesheet" href="../../_static/normalize.css" type="text/css">
            <link rel="stylesheet" href="../../_static/sphinx.css" type="text/css">
            <link rel="stylesheet" href="../../_static/main.css" type="text/css">
            <link rel="stylesheet" href="../../_static/flat.css" type="text/css">
            <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
            <link rel="stylesheet" href="../../_static/font-awesome.min.css" type="text/css">
        <link rel="shortcut icon" href="../../_static/favicon.ico" /><!-- Load modernizr and JQuery -->
        <script src="../../_static/vendor/modernizr-2.6.2.min.js"></script>
        <script src="//ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.min.js"></script>
        <script>window.jQuery || document.write('<script src="../../_static/vendor/jquery-1.8.2.min.js"><\/script>')</script>
        <script src="../../_static/plugins.js"></script>
        <script src="../../_static/main.js"></script>
        <link rel="search" title="Search" href="../../search.html" /><link rel="next" title="Create custom layers" href="create-custom-layers.html" /><link rel="prev" title="Layers" href="../layers.html" /><link rel="alternate" type="application/rss+xml" title="RSS" href="../../rss.html" /><script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '1.7.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        SOURCELINK_SUFFIX: '.txt',
        HAS_SOURCE:  true
      };
    </script><script type="text/javascript" src="../../_static/underscore.js"></script><script type="text/javascript" src="../../_static/doctools.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/javascript" src="../../_static/disqus.js"></script><script type="text/javascript" src="../../_static/js/google_analytics.js"></script><script type="text/javascript" src="../../_static/js/script.js"></script><script type="text/javascript" src="../../_static/js/copybutton.js"></script>

    <script type="text/javascript">
        $(document).ready(function () {
            // Scroll to content if on small screen
            if (screen.width < 480)
            {
                $(document).scrollTop(document.getElementsByTagName("article")[0].offsetTop - 44);
            }
        });
    </script>
    <style media="screen" type="text/css">
        img { max-width: 800px !important; }
        img[src="../_images/mnist-code-sample-home.png"] { max-width: 600px !important; }
        table { background-color: white; }
        table.docutils.citation  { background-color: inherit; }
        div.highlight { margin-bottom: 20px !important; }

        .limited-width { max-width: 800px; margin: auto; }
        .docutils { width: 100%; }
        a .docutils.literal {
            background-color: inherit !important;
            padding: 0px !important;
            color: #3bbc46 !important;
        }
        .docutils td { padding: 10px; }
        .section { word-wrap:break-word; }
        .descname { font-weight: bold; }
        .highlight-python + .figure { margin-top: 20px; }
        .dataframe { text-align: center !important; width: 100%; margin: 10px 0 10px 0; }
        .dataframe td { padding: 5px; }

        .math .gd { color: #000 !important; } /* Generic.Deleted */
        .math .m { color: #000 !important; } /* Literal.Number */
        .math .s { color: #000 !important; } /* Literal.String */
        .math .mf { color: #000 !important; } /* Literal.Number.Float */
        .math .mh { color: #000 !important; } /* Literal.Number.Hex */
        .math .mi { color: #000 !important; } /* Literal.Number.Integer */
        .math .mo { color: #000 !important; } /* Literal.Number.Oct */
        .math .sc { color: #000 !important; } /* Literal.String.Char */
        .math .s2 { color: #000 !important; } /* Literal.String.Double */
        .math .si { color: #000 !important; } /* Literal.String.Interpol */
        .math .sx { color: #000 !important; } /* Literal.String.Other */
        .math .s1 { color: #000 !important; } /* Literal.String.Single */
        .math .ss { color: #000 !important; } /* Literal.String.Symbol */
        .math .il { color: #000 !important; } /* Literal.Number.Integer.Long */

        /* Background for class and function names */
        dt[id^="neupy."] {
            background-color: #e6edf2;
            border: 1px solid #f8fafb;
            border-radius: 8px;
            padding: 10px 20px;
        }
        div[id^="module-neupy."] h1 {
            display: none;
        }

        /* Search input field */
        .search-input {
            width: 100%;
            padding: 10px;
            display: block;
        }
        .box {
          padding-bottom: 50px;
        }
        .search-input-container {
          width: 100%;
          vertical-align: middle;
          white-space: nowrap;
          position: relative;
        }
        .search-input-container input#search {
          width: 100%;
          height: 50px;
          padding-left: 45px;

          float: left;
          outline: none;
          border: 1px solid #ddd;

          box-sizing: border-box;
          -webkit-box-sizing: border-box;
          -moz-box-sizing: border-box;

          -webkit-border-radius: 5px;
          -moz-border-radius: 5px;
          border-radius: 5px;

          font-family: 'PT Sans', Helvetica, Arial, sans-serif;
          font-size: 12pt;
        }
        .search-input-container .icon {
          position: absolute;
          left: 0;
          top: 50%;
          margin-left: 17px;
          margin-top: 13px;
          z-index: 1;
          color: #93a4ad;
        }

        .docutils.field-list, .docutils.footnote {
            background-color: inherit;
        }
        .large-font {
            font-size: 1.4em !important;
        }
        .right-tag {
            float: right;
            margin-left: 36px !important;
            margin-right: 0px !important;
        }
        .short-description {
            /* We hidde description inside of the article */
            display: none;
        }
        .short-description img {
            max-height: 160px;
            max-width: 40% !important;
            margin-left: 8px;
        }
        #results-list ul.search {
            padding: 0;
            max-width: 900px;
            margin: auto;
        }

        #results-list .short-description {
            /* We show description text in the archive */
            display: block !important;
        }
        #results-list li p {
            margin-bottom: 5px;
            font-size: 0.9em;
        }
        #results-list li {
            background-color: #fff !important;
            margin-bottom: 10px;
            display: block !important;
            padding: 15px;
            border-bottom: 2px solid #ddd;
        }
        #results-list span.tag {
            display: inline-block;
            padding: 3px 4px;
            margin-right: 8px;
            position: relative;
            top: -2px;

            background: #888;
            color: #fff;

            font-size: 0.75em;
            font-weight: 600;
            line-height: 1;
            text-transform: uppercase;

            -webkit-border-radius: 2px;
            -moz-border-radius: 2px;
            border-radius: 2px;
        }
    </style></head>
    <body role="document">
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> or <a href="http://www.google.com/chromeframe/?redirect=true">activate Google Chrome Frame</a> to improve your experience.</p>
        <![endif]-->

      <div id="container"><header role="banner">
        <div>
          <h1><a href="../../pages/home.html">NeuPy</a></h1>
          <h2>Neural Networks in Python</h2>
        </div>
    </header>
    <nav role="navigation">
      <ul>
        <li class="main-nav">
          <a href="../../archive.html">Articles</a>
        </li>
        <li class="main-nav">
          <a href="../tutorials.html">Tutorials</a>
        </li>
        <li class="main-nav">
          <a href="../../pages/documentation.html">Documentation</a>
        </li>
        <li class="main-nav">
          <a href="../../pages/cheatsheet.html">Cheat sheet</a>
        </li>
        <li class="main-nav">
          <a href="../../pages/model_zoo.html">Model Zoo</a>
        </li>
      </ul>
    </nav>

<div class="main-container" role="main"><div class="main wrapper body clearfix"><article>
    <div class="section" id="basics">
<span id="layers-basics"></span><h1><a class="toc-backref" href="#id2">Basics</a></h1>
<div class="contents topic" id="contents">
<p class="topic-title first">Contents</p>
<ul class="simple">
<li><a class="reference internal" href="#basics" id="id2">Basics</a><ul>
<li><a class="reference internal" href="#join-layers" id="id3">Join layers</a></li>
<li><a class="reference internal" href="#inline-operator" id="id4">Inline operator</a></li>
<li><a class="reference internal" href="#input-layer" id="id5">Input layer</a></li>
<li><a class="reference internal" href="#build-networks-from-the-code" id="id6">Build networks from the code</a></li>
</ul>
</li>
<li><a class="reference internal" href="#mutlilayer-perceptron-mlp" id="id7">Mutlilayer Perceptron (MLP)</a></li>
<li><a class="reference internal" href="#convolutional-neural-networks-cnn" id="id8">Convolutional Neural Networks (CNN)</a><ul>
<li><a class="reference internal" href="#reshape" id="id9">Reshape</a></li>
<li><a class="reference internal" href="#convolution" id="id10">Convolution</a></li>
<li><a class="reference internal" href="#pooling" id="id11">Pooling</a></li>
</ul>
</li>
<li><a class="reference internal" href="#parallel-connections" id="id12">Parallel connections</a></li>
<li><a class="reference internal" href="#subnetworks" id="id13">Subnetworks</a></li>
</ul>
</div>
<p>Layer is a building block for constructible neural networks. NeuPy has a simple and flexible framework that allows to construct complex neural networks easily.</p>
<div class="section" id="join-layers">
<h2><a class="toc-backref" href="#id3">Join layers</a></h2>
<p>Let’s start with basics. The most useful function to define relations between layers is <span class="docutils literal"><span class="pre">layers.join</span></span>. It accepts sequence of layers and joins them into the network.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">neupy.layers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">join</span><span class="p">(</span><span class="n">Sigmoid</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">Sigmoid</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
<span class="go">&lt;unknown&gt; -&gt; [... 2 layers ...] -&gt; (?, 2)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">join</span><span class="p">(</span><span class="n">Sigmoid</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">Sigmoid</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="go">&lt;unknown&gt; -&gt; [... 2 layers ...] -&gt; (?, 1)</span>
</pre></div>
</div>
</div>
<div class="section" id="inline-operator">
<h2><a class="toc-backref" href="#id4">Inline operator</a></h2>
<p>Also, NeuPy provides a special <strong>inline</strong> operator that helps to define sequential relations between layers.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">neupy.layers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Sigmoid</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">&gt;&gt;</span> <span class="n">Sigmoid</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">&lt;unknown&gt; -&gt; [... 2 layers ...] -&gt; (?, 1)</span>
</pre></div>
</div>
<p>Code above does exactly the same as <span class="docutils literal"><span class="pre">join(Sigmoid(2),</span> <span class="pre">Sigmoid(1))</span></span>.</p>
</div>
<div class="section" id="input-layer">
<h2><a class="toc-backref" href="#id5">Input layer</a></h2>
<p>In the network, shape of the expected input has to be specified explicitly. It’s possible to define expected input shape using the <a class="reference internal" href="../../apidocs/neupy.layers.base.html#neupy.layers.base.Input" title="neupy.layers.base.Input"><span class="xref py py-class docutils literal"><span class="pre">Input</span></span></a> layer.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">neupy.layers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Input</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="o">&gt;&gt;</span> <span class="n">Sigmoid</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">&gt;&gt;</span> <span class="n">Sigmoid</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">(?, 3) -&gt; [... 3 layers ...] -&gt; (?, 1)</span>
</pre></div>
</div>
<p>The <a class="reference internal" href="../../apidocs/neupy.layers.base.html#neupy.layers.base.Input" title="neupy.layers.base.Input"><span class="xref py py-class docutils literal"><span class="pre">Input</span></span></a> layer expects features shape of each individual sample passed through the network as a first argument. In the example above, we say that each input sample will have 3-dimensional features.</p>
<p>Multi-dimensional inputs can be specified as a tuple.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">Input</span><span class="p">((</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="o">&gt;&gt;</span> <span class="n">Convolution</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">16</span><span class="p">))</span> <span class="o">&gt;&gt;</span> <span class="n">Relu</span><span class="p">()</span>
<span class="go">(?, 28, 28, 1) -&gt; [... 3 layers ...] -&gt; (?, 26, 26, 16)</span>
</pre></div>
</div>
<p>In the example above, we specified network that expects images as an input. Each image will have height and width equal to 28x28 and we expect that each image will have only one channel.</p>
<p>It’s also fine to avoid specifying some of the dimension when value is unknown in advance. Unknown dimensions can be specified with value <span class="docutils literal"><span class="pre">None</span></span>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">Input</span><span class="p">((</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span> <span class="o">&gt;&gt;</span> <span class="n">Convolution</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">16</span><span class="p">))</span> <span class="o">&gt;&gt;</span> <span class="n">Relu</span><span class="p">()</span>
<span class="go">(?, ?, ?, 3) -&gt; [... 3 layers ...] -&gt; (?, ?, ?, 16)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Input</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span> <span class="o">&gt;&gt;</span> <span class="n">Relu</span><span class="p">()</span>
<span class="go">(?, ?) -&gt; [... 2 layers ...] -&gt; (?, ?)</span>
</pre></div>
</div>
</div>
<div class="section" id="build-networks-from-the-code">
<h2><a class="toc-backref" href="#id6">Build networks from the code</a></h2>
<p>For more complex networks, it’s possible to build them from the code. For example, we can dynamically specify depth of the network and build it in the loop.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">neupy.layers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">network</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">size</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">network</span> <span class="o">=</span> <span class="n">network</span> <span class="o">&gt;&gt;</span> <span class="n">Sigmoid</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">network</span>
<span class="go">(?, 10) -&gt; [... 5 layers ...] -&gt; (?, 2)</span>
</pre></div>
</div>
<p>Code can be simplified by replacing <span class="docutils literal"><span class="pre">network</span> <span class="pre">=</span> <span class="pre">network</span> <span class="pre">&gt;&gt;</span> <span class="pre">Sigmoid(size)</span></span> with short expression - <span class="docutils literal"><span class="pre">network</span> <span class="pre">&gt;&gt;=</span> <span class="pre">Sigmoid(size)</span></span>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">network</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">size</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">network</span> <span class="o">&gt;&gt;=</span> <span class="n">Sigmoid</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">network</span>
<span class="go">(?, 10) -&gt; [... 5 layers ...] -&gt; (?, 2)</span>
</pre></div>
</div>
<p>Both examples are equivalent to the code below.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">network</span> <span class="o">=</span> <span class="n">join</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">Input</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">Sigmoid</span><span class="p">(</span><span class="mi">8</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">Sigmoid</span><span class="p">(</span><span class="mi">6</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">Sigmoid</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">Sigmoid</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">network</span>
<span class="go">(?, 10) -&gt; [... 5 layers ...] -&gt; (?, 2)</span>
</pre></div>
</div>
<br></div>
</div>
<div class="section" id="mutlilayer-perceptron-mlp">
<h1><a class="toc-backref" href="#id7">Mutlilayer Perceptron (MLP)</a></h1>
<p>In this section, we are going to learn more about layers with activation function which are the most important building blocks for the MLP networks. Let’s consider the following example.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">neupy.layers</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">network</span> <span class="o">=</span> <span class="n">join</span><span class="p">(</span>
    <span class="n">Input</span><span class="p">(</span><span class="mi">784</span><span class="p">),</span>
    <span class="n">Relu</span><span class="p">(</span><span class="mi">500</span><span class="p">),</span>
    <span class="n">Relu</span><span class="p">(</span><span class="mi">300</span><span class="p">),</span>
    <span class="n">Softmax</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="figure align-center">
<img alt="Feedforward connections in NeuPy" src="../../_images/feedforward-graph-connection.png" />
</div>
<p>You can see from the figure above that each layer with activation function defines dense connection. The NeuPy combines layer that applies linear transformation with non-linear activation function into one layer. It’s possible to break down this layer into two separate operations.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">network</span> <span class="o">=</span> <span class="n">join</span><span class="p">(</span>
    <span class="n">Input</span><span class="p">(</span><span class="mi">784</span><span class="p">),</span>

    <span class="n">Linear</span><span class="p">(</span><span class="mi">500</span><span class="p">),</span>
    <span class="n">Relu</span><span class="p">(),</span>

    <span class="n">Linear</span><span class="p">(</span><span class="mi">300</span><span class="p">),</span>
    <span class="n">Relu</span><span class="p">(),</span>

    <span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
    <span class="n">Softmax</span><span class="p">(),</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Example above defines exactly the same architecture as before. We just split each layer with activation function into simple operations. Operation in the <span class="docutils literal"><span class="pre">Relu(500)</span></span> is the same as <span class="docutils literal"><span class="pre">Linear(500)</span> <span class="pre">&gt;&gt;</span> <span class="pre">Relu()</span></span>.</p>
</div>
<div class="section" id="convolutional-neural-networks-cnn">
<h1><a class="toc-backref" href="#id8">Convolutional Neural Networks (CNN)</a></h1>
<p>NeuPy supports Convolutional Neural Networks. Let’s consider the following example.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">neupy.layers</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">convnet</span> <span class="o">=</span> <span class="n">join</span><span class="p">(</span>
    <span class="n">Input</span><span class="p">((</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>

    <span class="n">Convolution</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">)),</span>
    <span class="n">Relu</span><span class="p">(),</span>
    <span class="n">Convolution</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">48</span><span class="p">)),</span>
    <span class="n">Relu</span><span class="p">(),</span>
    <span class="n">MaxPooling</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>

    <span class="n">Reshape</span><span class="p">(),</span>
    <span class="n">Softmax</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="figure align-center">
<img alt="Convolutional Neural Network in NeuPy" src="../../_images/conv-graph-connection.png" />
</div>
<p>There are a few new layers that we are going to explore in more details.</p>
<div class="section" id="reshape">
<h2><a class="toc-backref" href="#id9">Reshape</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Reshape</span><span class="p">()</span>
</pre></div>
</div>
<p>This layer does the same as the <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html">numpy.reshape</a> function. The main different is that argument that defines new shape has default value. When shape is not specified explicitly, the <a class="reference internal" href="../../apidocs/neupy.layers.reshape.html#neupy.layers.reshape.Reshape" title="neupy.layers.reshape.Reshape"><span class="xref py py-class docutils literal"><span class="pre">Reshape</span></span></a> layer converts input to 2D matrix.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">neupy.layers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Input</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span> <span class="o">&gt;&gt;</span> <span class="n">Reshape</span><span class="p">()</span>
<span class="go">(?, 3, 10, 10) -&gt; [... 2 layers ...] -&gt; (?, 300)</span>
</pre></div>
</div>
<p>Also, we can specify expected output shape as a parameters for the <a class="reference internal" href="../../apidocs/neupy.layers.reshape.html#neupy.layers.reshape.Reshape" title="neupy.layers.reshape.Reshape"><span class="xref py py-class docutils literal"><span class="pre">Reshape</span></span></a> layer.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">Input</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span> <span class="o">&gt;&gt;</span> <span class="n">Reshape</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="go">(?, 3, 10, 10) -&gt; [... 2 layers ...] -&gt; (?, 3, 100)</span>
</pre></div>
</div>
</div>
<div class="section" id="convolution">
<h2><a class="toc-backref" href="#id10">Convolution</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Convolution</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
</pre></div>
</div>
<p>Each of the convolutional layers takes one mandatory argument that defines convolutional filter. Input argument contains three integers <span class="docutils literal"><span class="pre">(number</span> <span class="pre">of</span> <span class="pre">rows,</span> <span class="pre">number</span> <span class="pre">of</span> <span class="pre">columns,</span> <span class="pre">number</span> <span class="pre">of</span> <span class="pre">filters)</span></span>. Information about the stack size was taken from the previous layer.</p>
<p>NeuPy supports only 2D convolution, but it’s trivial to make a 1D convolution. We can, for instance, set up width equal to <span class="docutils literal"><span class="pre">1</span></span> like in the following example.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">neupy.layers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">join</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">Input</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">30</span><span class="p">)),</span>
<span class="gp">... </span>    <span class="n">Reshape</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">30</span><span class="p">)),</span>
<span class="gp">... </span>    <span class="n">Convolution</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">)),</span>
<span class="gp">... </span><span class="p">)</span>
</pre></div>
</div>
<p>Convolutional layer has a few other attributes that you can modify. You can check the <a class="reference internal" href="../../apidocs/neupy.layers.convolutions.html#neupy.layers.convolutions.Convolution" title="neupy.layers.convolutions.Convolution"><span class="xref py py-class docutils literal"><span class="pre">Convolutional</span></span></a> layer’s documentation and find more information about its arguments.</p>
</div>
<div class="section" id="pooling">
<h2><a class="toc-backref" href="#id11">Pooling</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">MaxPooling</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
<p>Pooling layer has also one mandatory argument that defines a factor by which to downscale <span class="docutils literal"><span class="pre">(vertical,</span> <span class="pre">horizontal)</span></span>. The <span class="docutils literal"><span class="pre">(2,</span> <span class="pre">2)</span></span> value will halve the image in each dimension.</p>
<p>Pooling works only with 4D inputs, but you can use in case of 3D if you apply the same trick that we did for convolutional layer. You need to define one of the downscale factors equal to <span class="docutils literal"><span class="pre">1</span></span>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">neupy.layers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">join</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">Input</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">30</span><span class="p">)),</span>
<span class="gp">... </span>    <span class="n">Reshape</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">30</span><span class="p">)),</span>
<span class="gp">... </span>    <span class="n">MaxPooling</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
<span class="gp">... </span><span class="p">)</span>
</pre></div>
</div>
<br></div>
</div>
<div class="section" id="parallel-connections">
<h1><a class="toc-backref" href="#id12">Parallel connections</a></h1>
<p>Any connection between layers in NeuPy is a <a class="reference external" href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">Directional Acyclic Graph (DAG)</a>. So far we’ve encountered only sequential connections which is just a simple case of DAG. In NeuPy, we are allowed to build much more complex relations between layers.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">neupy.layers</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">network</span> <span class="o">=</span> <span class="n">join</span><span class="p">(</span>
    <span class="n">Input</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
    <span class="n">parallel</span><span class="p">([</span>
        <span class="n">Convolution</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span> <span class="o">&gt;&gt;</span> <span class="n">Relu</span><span class="p">(),</span>
        <span class="n">MaxPooling</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
    <span class="p">],</span> <span class="p">[</span>
        <span class="n">Convolution</span><span class="p">((</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">16</span><span class="p">))</span> <span class="o">&gt;&gt;</span> <span class="n">Relu</span><span class="p">(),</span>
    <span class="p">]),</span>
    <span class="n">Concatenate</span><span class="p">(),</span>

    <span class="n">Reshape</span><span class="p">(),</span>
    <span class="n">Softmax</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="figure align-center">
<img alt="Parallel connections in NeuPy" src="../../_images/conv-parallel-connection.png" />
</div>
<p>Also its possible to define the same graph relations between layers with inline operator.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">neupy.layers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_layer</span> <span class="o">=</span> <span class="n">Input</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">left_branch</span> <span class="o">=</span> <span class="n">join</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">Convolution</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span> <span class="o">&gt;&gt;</span> <span class="n">Relu</span><span class="p">(),</span>
<span class="gp">... </span>    <span class="n">MaxPooling</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
<span class="gp">... </span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">right_branch</span> <span class="o">=</span> <span class="n">Convolution</span><span class="p">((</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">16</span><span class="p">))</span> <span class="o">&gt;&gt;</span> <span class="n">Relu</span><span class="p">()</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">network</span> <span class="o">=</span> <span class="n">input_layer</span> <span class="o">&gt;&gt;</span> <span class="p">(</span><span class="n">left_branch</span> <span class="o">|</span> <span class="n">right_branch</span><span class="p">)</span> <span class="o">&gt;&gt;</span> <span class="n">Concatenate</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">network</span> <span class="o">=</span> <span class="n">network</span> <span class="o">&gt;&gt;</span> <span class="n">Reshape</span><span class="p">()</span> <span class="o">&gt;&gt;</span> <span class="n">Softmax</span><span class="p">()</span>
</pre></div>
</div>
<p>Notice that we’ve used new operator. The <span class="docutils literal"><span class="pre">|</span></span> operator helps us to define parallel connections.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">input_layer</span> <span class="o">&gt;&gt;</span> <span class="p">(</span><span class="n">left_branch</span> <span class="o">|</span> <span class="n">right_branch</span><span class="p">)</span>
</pre></div>
</div>
<p>and many to one</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">left_branch</span> <span class="o">|</span> <span class="n">right_branch</span><span class="p">)</span> <span class="o">&gt;&gt;</span> <span class="n">Concatenate</span><span class="p">()</span>
</pre></div>
</div>
<br></div>
<div class="section" id="subnetworks">
<span id="id1"></span><h1><a class="toc-backref" href="#id13">Subnetworks</a></h1>
<p><strong>Subnetworks</strong> is a method that improves readability of the neural network architecture. Instead of explaining, it’s much easier to show the main advantage of this technique. Here is an example of the simple convolutional network.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">neupy.layers</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">network</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
    <span class="n">Input</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>

    <span class="n">Convolution</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
    <span class="n">Relu</span><span class="p">(),</span>
    <span class="n">BatchNorm</span><span class="p">(),</span>

    <span class="n">Convolution</span><span class="p">((</span><span class="mi">48</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
    <span class="n">Relu</span><span class="p">(),</span>
    <span class="n">BatchNorm</span><span class="p">(),</span>
    <span class="n">MaxPooling</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>

    <span class="n">Convolution</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
    <span class="n">Relu</span><span class="p">(),</span>
    <span class="n">BatchNorm</span><span class="p">(),</span>
    <span class="n">MaxPooling</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>

    <span class="n">Reshape</span><span class="p">(),</span>

    <span class="n">Relu</span><span class="p">(</span><span class="mi">1024</span><span class="p">),</span>
    <span class="n">BatchNorm</span><span class="p">(),</span>

    <span class="n">Softmax</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Does it look simple to you? Most likely not. However, this is a really simple neural network. It looks a bit complicated, because it contains a lot of simple layers that usually combined into one. For instance, non-linearity like <a class="reference internal" href="../../apidocs/neupy.layers.activations.html#neupy.layers.activations.Relu" title="neupy.layers.activations.Relu"><span class="xref py py-class docutils literal"><span class="pre">Relu</span></span></a> is usually built-in inside the <a class="reference internal" href="../../apidocs/neupy.layers.convolutions.html#neupy.layers.convolutions.Convolution" title="neupy.layers.convolutions.Convolution"><span class="xref py py-class docutils literal"><span class="pre">Convolution</span></span></a> layer. So instead of combining simple layers in one complicated, in NeuPy it’s better to use subnetworks. Here is an example on how to re-write network’s structure from the previous example in terms of subnetworks.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">network</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
    <span class="n">Input</span><span class="p">((</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>

    <span class="n">Convolution</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span> <span class="o">&gt;&gt;</span> <span class="n">Relu</span><span class="p">()</span> <span class="o">&gt;&gt;</span> <span class="n">BatchNorm</span><span class="p">(),</span>
    <span class="n">Convolution</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">48</span><span class="p">))</span> <span class="o">&gt;&gt;</span> <span class="n">Relu</span><span class="p">()</span> <span class="o">&gt;&gt;</span> <span class="n">BatchNorm</span><span class="p">(),</span>
    <span class="n">MaxPooling</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>

    <span class="n">Convolution</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">))</span> <span class="o">&gt;&gt;</span> <span class="n">Relu</span><span class="p">()</span> <span class="o">&gt;&gt;</span> <span class="n">BatchNorm</span><span class="p">(),</span>
    <span class="n">MaxPooling</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>

    <span class="n">Reshape</span><span class="p">(),</span>

    <span class="n">Relu</span><span class="p">(</span><span class="mi">1024</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">BatchNorm</span><span class="p">(),</span>
    <span class="n">Softmax</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
<p>As you can see, we use an ability to organize sequence of simple layer in one small network. Each subnetwork defines a sequence of simple operations. You can think about subnetworks as a simple way to define more complicated layers. But instead of creating redundant classes or functions, that define complex layers, we can define everything in place. In addition, it improves the readability, because now everybody can see order of these simple operations inside the subnetwork.</p>
</div>

    <div class="postmeta">
        
        
        
        </div><ul class="related clearfix">
            <li class="left"> &laquo; <a href="../layers.html">Layers</a></li>
            <li class="right"><a href="create-custom-layers.html">Create custom layers</a> &raquo; </li>
        </ul></article><aside class="sidebar"><section><div class="widget" id="searchbox" role="search">
    <h1><a href="#searchbox">Search</a></h1>
    <form action="../../search.html" method="get">
          <div class="box">
            <div class="search-input-container">
                <span class="icon"><i class="fa fa-search"></i></span>
                <input type="search" name="q" id="search" placeholder="Search..." />
            </div>
          </div>
    </form>
</div></section><section><div class="widget">
    <h1>Install NeuPy</h1>
    <div class="highligh-bash">
        <div class="highlight">
            <pre>pip install neupy</pre>
        </div>
    </div>
    <p>
        <div>Learn more about NeuPy reading <a href="../tutorials.html">tutorials</a> and <a href="../../pages/documentation.html">documentation</a>.</div>
    </p>
</div></section><section><div class="widget">
    <h1>Issues and feature requests</h1>
    <p>
        If you find a bug or want to suggest a new feature feel free to
        <a href="https://github.com/itdxer/neupy/issues/new">create an issue</a>
        on Github
    </p>
</div></section></aside></div> <!-- #main --></div> <!-- #main-container -->

        <div class="footer-container" role="contentinfo"><footer class="wrapper">&copy; Copyright 2015 - 2019, Yurii Shevchuk. Powered by <a href="http://www.tinkerer.me/">Tinkerer</a> and <a href="http://sphinx.pocoo.org/">Sphinx</a>.</footer></div> <!-- footer-container -->

      </div> <!--! end of #container --><script type="text/javascript">    var disqus_shortname = "neupy";    disqus_count();</script><!--[if lt IE 7 ]>
          <script src="//ajax.googleapis.com/ajax/libs/chrome-frame/1.0.3/CFInstall.min.js"></script>
          <script>window.attachEvent('onload',function(){CFInstall.check({mode:'overlay'})})</script>
        <![endif]-->
    </body>
</html>