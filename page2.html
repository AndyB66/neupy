<!DOCTYPE html><!--[if lt IE 7]>      <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js"> <!--<![endif]-->
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <meta name="description" content="NeuPy is a Python library for Artificial Neural Networks. NeuPy supports many different types of Neural Networks from a simple perceptron to deep learning models.">
        <meta name="viewport" content="width=device-width">
        <title>Page 2 &mdash; NeuPy</title>
            <link rel="stylesheet" href="_static/normalize.css" type="text/css">
            <link rel="stylesheet" href="_static/sphinx.css" type="text/css">
            <link rel="stylesheet" href="_static/main.css" type="text/css">
            <link rel="stylesheet" href="_static/flat.css" type="text/css">
            <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
            <link rel="stylesheet" href="_static/font-awesome.min.css" type="text/css">
        <link rel="shortcut icon" href="_static/favicon.ico" /><!-- Load modernizr and JQuery -->
        <script src="_static/vendor/modernizr-2.6.2.min.js"></script>
        <script src="//ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.min.js"></script>
        <script>window.jQuery || document.write('<script src="_static/vendor/jquery-1.8.2.min.js"><\/script>')</script>
        <script src="_static/plugins.js"></script>
        <script src="_static/main.js"></script>
        <link rel="search" title="Search" href="search.html" /><link rel="prev" title="Newer" href="page1.html" /><link rel="alternate" type="application/rss+xml" title="RSS" href="rss.html" /><script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.7.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        SOURCELINK_SUFFIX: '.txt',
        HAS_SOURCE:  true
      };
    </script><script type="text/javascript" src="_static/underscore.js"></script><script type="text/javascript" src="_static/doctools.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/javascript" src="_static/disqus.js"></script><script type="text/javascript" src="_static/js/google_analytics.js"></script><script type="text/javascript" src="_static/js/script.js"></script><script type="text/javascript" src="_static/js/copybutton.js"></script>

    <script type="text/javascript">
        $(document).ready(function () {
            // Scroll to content if on small screen
            if (screen.width < 480)
            {
                $(document).scrollTop(document.getElementsByTagName("article")[0].offsetTop - 44);
            }
        });
    </script>
    <style media="screen" type="text/css">
        img[src="../_images/mnist-code-sample-home.png"] { max-width: 600px !important; }
        table { background-color: white; }
        table.docutils.citation  { background-color: inherit; }
        div.highlight { margin-bottom: 20px !important; }

        .limited-width { max-width: 800px; margin: auto; }
        .docutils { width: 100%; }
        a .docutils.literal {
            background-color: inherit !important;
            padding: 0px !important;
            color: #3bbc46 !important;
        }
        .docutils td { padding: 10px; }
        .section { word-wrap:break-word; }
        .descname { font-weight: bold; }
        .highlight-python + .figure { margin-top: 20px; }
        .dataframe { text-align: center !important; width: 100%; margin: 10px 0 10px 0; }
        .dataframe td { padding: 5px; }

        .math .gd { color: #000 !important; } /* Generic.Deleted */
        .math .m { color: #000 !important; } /* Literal.Number */
        .math .s { color: #000 !important; } /* Literal.String */
        .math .mf { color: #000 !important; } /* Literal.Number.Float */
        .math .mh { color: #000 !important; } /* Literal.Number.Hex */
        .math .mi { color: #000 !important; } /* Literal.Number.Integer */
        .math .mo { color: #000 !important; } /* Literal.Number.Oct */
        .math .sc { color: #000 !important; } /* Literal.String.Char */
        .math .s2 { color: #000 !important; } /* Literal.String.Double */
        .math .si { color: #000 !important; } /* Literal.String.Interpol */
        .math .sx { color: #000 !important; } /* Literal.String.Other */
        .math .s1 { color: #000 !important; } /* Literal.String.Single */
        .math .ss { color: #000 !important; } /* Literal.String.Symbol */
        .math .il { color: #000 !important; } /* Literal.Number.Integer.Long */

        /* Background for class and function names */
        dt[id^="neupy."] {
            background-color: #e6edf2;
            border: 1px solid #f8fafb;
            border-radius: 8px;
            padding: 10px 20px;
        }
        div[id^="module-neupy."] h1 {
            display: none;
        }

        /* Search input field */
        .search-input {
            width: 100%;
            padding: 10px;
            display: block;
        }
        .box {
          padding-bottom: 50px;
        }
        .search-input-container {
          width: 100%;
          vertical-align: middle;
          white-space: nowrap;
          position: relative;
        }
        .search-input-container input#search {
          width: 100%;
          height: 50px;
          padding-left: 45px;

          float: left;
          outline: none;
          border: 1px solid #ddd;

          box-sizing: border-box;
          -webkit-box-sizing: border-box;
          -moz-box-sizing: border-box;

          -webkit-border-radius: 5px;
          -moz-border-radius: 5px;
          border-radius: 5px;

          font-family: 'PT Sans', Helvetica, Arial, sans-serif;
          font-size: 12pt;
        }
        .search-input-container .icon {
          position: absolute;
          left: 0;
          top: 50%;
          margin-left: 17px;
          margin-top: 13px;
          z-index: 1;
          color: #93a4ad;
        }

        .docutils.field-list, .docutils.footnote {
            background-color: inherit;
        }
        .large-font {
            font-size: 1.4em !important;
        }
        .right-tag {
            float: right;
            margin-left: 36px !important;
            margin-right: 0px !important;
        }
        .short-description {
            /* We hidde description inside of the article */
            display: none;
        }
        .short-description img {
            max-height: 160px;
            max-width: 40% !important;
            margin-left: 8px;
        }
        #results-list ul.search {
            padding: 0;
            max-width: 900px;
            margin: auto;
        }

        #results-list .short-description {
            /* We show description text in the archive */
            display: block !important;
        }
        #results-list li p {
            margin-bottom: 5px;
            font-size: 0.9em;
        }
        #results-list li {
            background-color: #fff !important;
            margin-bottom: 10px;
            display: block !important;
            padding: 15px;
            border-bottom: 2px solid #ddd;
        }
        #results-list span.tag {
            display: inline-block;
            padding: 3px 4px;
            margin-right: 8px;
            position: relative;
            top: -2px;

            background: #888;
            color: #fff;

            font-size: 0.75em;
            font-weight: 600;
            line-height: 1;
            text-transform: uppercase;

            -webkit-border-radius: 2px;
            -moz-border-radius: 2px;
            border-radius: 2px;
        }
    </style></head>
    <body role="document">
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> or <a href="http://www.google.com/chromeframe/?redirect=true">activate Google Chrome Frame</a> to improve your experience.</p>
        <![endif]-->

      <div id="container"><header role="banner">
        <div>
          <h1><a href="pages/home.html">NeuPy</a></h1>
          <h2>Neural Networks in Python</h2>
        </div>
    </header>
    <nav role="navigation">
      <ul>
        <li class="main-nav">
          <a href="archive.html">Articles</a>
        </li>
        <li class="main-nav">
          <a href="docs/tutorials.html">Tutorials</a>
        </li>
        <li class="main-nav">
          <a href="pages/documentation.html">Documentation</a>
        </li>
        <li class="main-nav">
          <a href="pages/cheatsheet.html">Cheat sheet</a>
        </li>
        <li class="main-nav">
          <a href="pages/model_zoo.html">Model Zoo</a>
        </li>
      </ul>
    </nav>

<div class="main-container" role="main"><div class="main wrapper body clearfix"><article><div class="timestamp postmeta">
            <span>July 04, 2015</span>
        </div>
        <div class="section">
            <div class="section" id="visualize-algorithms-based-on-the-backpropagation">
<h1><a href="2015/07/04/visualize_backpropagation_algorithms.html"><a class="toc-backref" href="#id3">Visualize Algorithms based on the backpropagation</a></a></h1>
<div class="contents topic" id="contents">
<p class="topic-title first">Contents</p>
<ul class="simple">
<li><a class="reference internal" href="2015/07/04/visualize_backpropagation_algorithms.html#visualize-algorithms-based-on-the-backpropagation" id="id3">Visualize Algorithms based on the backpropagation</a><ul>
<li><a class="reference internal" href="2015/07/04/visualize_backpropagation_algorithms.html#checking-data" id="id4">Checking data</a></li>
<li><a class="reference internal" href="2015/07/04/visualize_backpropagation_algorithms.html#initialize-contour" id="id5">Initialize contour</a></li>
<li><a class="reference internal" href="2015/07/04/visualize_backpropagation_algorithms.html#id1" id="id6">Visualize algorithms based on the Backpropagation</a><ul>
<li><a class="reference internal" href="2015/07/04/visualize_backpropagation_algorithms.html#gradient-descent" id="id7">Gradient Descent</a></li>
<li><a class="reference internal" href="2015/07/04/visualize_backpropagation_algorithms.html#momentum" id="id8">Momentum</a></li>
<li><a class="reference internal" href="2015/07/04/visualize_backpropagation_algorithms.html#rprop" id="id9">RPROP</a></li>
<li><a class="reference internal" href="2015/07/04/visualize_backpropagation_algorithms.html#irprop" id="id10">iRPROP+</a></li>
<li><a class="reference internal" href="2015/07/04/visualize_backpropagation_algorithms.html#gradient-descent-and-golden-search" id="id11">Gradient Descent and Golden Search</a></li>
</ul>
</li>
<li><a class="reference internal" href="2015/07/04/visualize_backpropagation_algorithms.html#bring-them-all-together" id="id12">Bring them all together</a></li>
<li><a class="reference internal" href="2015/07/04/visualize_backpropagation_algorithms.html#summary" id="id13">Summary</a></li>
</ul>
</li>
</ul>
</div>
<p>Typical neural networks have mullions of parameters and it’s quite difficult to visualize its training process. In the article, we visualize training of the network that has only 2 parameters. It allows us to explore different training algorithms and see how it behaves during the training.</p>
<div class="section" id="checking-data">
<h2><a class="toc-backref" href="#id4">Checking data</a></h2>
<p>First of all we need to define simple dataset which contains 6 points with two features.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span>
<span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">],</span>
<span class="p">])</span>
</pre></div>
</div>
<p>So we can make a scatter plot and look closer at this dots.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<div class="figure align-center">
<a class="reference internal image-reference" href="_images/bp-vis-scatter.png"><img alt="Dataset scatter plot" src="_images/bp-vis-scatter.png" style="width: 80%;"/></a>
</div>
<p>From the figure above we can clearly see that all dots are linearly separable and we are able to solve this problem with simple perceptron. But the goal of this article is to make clear visualization of learning process for different algorithm based on the backpropagation method, so the problem has to be as simple as possible, because in other cases it will be complex to visualize.</p>
<p>So, since the problem is linear separable we can solve it without hidden layers in network. There are two features and two classes, so we can build network which will take 2 input values and will produce 1 output. We need just two weights, so we can visualize them in contour plot.</p>
</div>
<div class="section" id="initialize-contour">
<h2><a class="toc-backref" href="#id5">Initialize contour</a></h2>
<p>I won’t  add all code related to the plots building in the article. In case if you are interested you can check the main script <a class="reference external" href="https://github.com/itdxer/neupy/blob/master/examples/mlp/gd_algorithms_visualization.py">here</a>.</p>
<a class="reference internal image-reference" href="_images/raw-contour-plot.png"><img alt="Approximation function contour plot" class="align-center" src="_images/raw-contour-plot.png" style="width: 80%;"/></a>
<p>The plot above shows error rate that depends on the network’s weights. The best result corresponds to the smallest error value. The best weights combination for this problem should be near the bottom right corner in the white area.</p>
<p>Next, we are going to look at 5 algorithms based on the Backpropagation. They are:</p>
<ul class="simple">
<li>Gradient descent</li>
<li>Momentum</li>
<li>RPROP</li>
<li>iRPROP+</li>
<li>Gradient Descent + Golden Search</li>
</ul>
<p>Let’s define start point for our algorithms. I’ve chosen the <cite>(-4, -4)</cite> point, because at this point network gives bad results and it will be interesting to observe the learning progress from a bad initialization point. In the script you can set up any other starting point you like.</p>
<p>This function will train the network until the error will be smaller than <cite>0.125</cite>. Every network starts at place with coordinates <cite>(-4, -4)</cite> and finishes near the point with the error value lower than <cite>0.125</cite>.</p>
</div>
<div class="section" id="id1">
<h2><a class="toc-backref" href="#id6">Visualize algorithms based on the Backpropagation</a></h2>
<div class="section" id="gradient-descent">
<h3><a class="toc-backref" href="#id7">Gradient Descent</a></h3>
<p>Let’s primarily check <a class="reference internal" href="apidocs/neupy.algorithms.gd.base.html#neupy.algorithms.gd.base.GradientDescent" title="neupy.algorithms.gd.base.GradientDescent"><span class="xref py py-class docutils literal"><span class="pre">Gradient</span> <span class="pre">Descent</span></span></a>.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="_images/bp-steps.png"><img alt="Weight update steps for the Gradient Descent" src="_images/bp-steps.png" style="width: 80%;"/></a>
</div>
<p>Gradient Descent got to the value close to 0.125 using 797 steps and this black curve is just tiny steps of gradient descent algorithm. We can zoom it and look even closer.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="_images/bp-steps-zoom.png"><img alt="Zoomed weight update steps for the Gradient Descent" src="_images/bp-steps-zoom.png" style="width: 80%;"/></a>
</div>
<p>Now we can see some information about gradient descent algorithm. All steps for gradient descent algorithm have approximately similar magnitude. Their direction doesn’t vary because contours in the zoomed picture are parallel to each other and in it we can see that there are still a lot of steps that are needed to be made to achieve the minimum. Also we can see that small vectors are perpendicular to the contour.</p>
<p>The problem is that the step size is a very sensitive parameter for the gradient descent. In typical problem we won’t be able to visualize the learning progress and we won’t have an ability to see that our updates over the epochs are inefficient. For this result I’ve used step size equal to <span class="docutils literal"><span class="pre">0.3</span></span>, but if we increased it to <span class="docutils literal"><span class="pre">10</span></span> we would reach our goal in <span class="docutils literal"><span class="pre">25</span></span> steps. I haven’t added any improvements to make a fair comparison to other algorithms in the summary chapter.</p>
</div>
<div class="section" id="momentum">
<h3><a class="toc-backref" href="#id8">Momentum</a></h3>
<p>Now let’s look at another very popular algorithm - <a class="reference internal" href="apidocs/neupy.algorithms.gd.momentum.html#neupy.algorithms.gd.momentum.Momentum" title="neupy.algorithms.gd.momentum.Momentum"><span class="xref py py-class docutils literal"><span class="pre">Momentum</span></span></a>.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="_images/momentum-steps.png"><img alt="Momentum steps" src="_images/momentum-steps.png" style="width: 80%;"/></a>
</div>
<p><a class="reference internal" href="apidocs/neupy.algorithms.gd.momentum.html#neupy.algorithms.gd.momentum.Momentum" title="neupy.algorithms.gd.momentum.Momentum"><span class="xref py py-class docutils literal"><span class="pre">Momentum</span></span></a> got to the value close to 0.125 by 92 steps, which is more than 8 times less than for the gradient descent. The basic idea behind <a class="reference internal" href="apidocs/neupy.algorithms.gd.momentum.html#neupy.algorithms.gd.momentum.Momentum" title="neupy.algorithms.gd.momentum.Momentum"><span class="xref py py-class docutils literal"><span class="pre">Momentum</span></span></a> algorithm is that it accumulates gradients from the previous epochs. It means that if the gradient has the same direction after each epoch weight update vector magnitude will increase. But if the gradient stars changing its direction weight update vector magnitude will decrease. Check the figure again. Imagine that you’re standing at a skatepark. Than you throw a ball into a half-pipe in a way that makes it roll smoothly on the surface. While it rolls down the gravity force drags it down and it makes the ball roll faster and faster. Let’s get back to the <a class="reference internal" href="apidocs/neupy.algorithms.gd.momentum.html#neupy.algorithms.gd.momentum.Momentum" title="neupy.algorithms.gd.momentum.Momentum"><span class="xref py py-class docutils literal"><span class="pre">Momentum</span></span></a> algorithm and try to find these properties in the plot.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="_images/momentum-steps-zoom.png"><img alt="Momentum steps zoom on increasing weight update size" src="_images/momentum-steps-zoom.png" style="width: 80%;"/></a>
</div>
<p>When we zoom the plot we can see that the direction for weight update vectors is almost the same and gradient’s direction doesn’t change after every epoch. In the picture above the vector which is the last on the right is bigger than the first one on the same plot on the left. Since it always moves forward it speeds up.</p>
<p>Let’s get back to the ball example. What happens when the ball reaches the pit of the half-pipe for the first time? Will it stop? Of course not. Ball gained enough speed for moving. So it will go up. But after that the ball will start to slow down and its amplitude will become smaller and smaller, because of the gravity force, that will continue to push it down to the pit and eventually it will stop to move. Let’s try to find the similar behavior in the same plot.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="_images/momentum-steps-zoom-decrease.png"><img alt="Momentum steps zoom on decreasing weight update size" src="_images/momentum-steps-zoom-decrease.png" style="width: 80%;"/></a>
</div>
<p>From the figure above it’s clear that weight update magnitude became smaller. Like a ball that slows down and changes its direction towards the minimum.</p>
<p>And finally to make it even more intuitive you can check weight update trajectory in 3D plot. It looks much more like the ball and half-pipe in skatepark analogy.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="_images/momentum-3d-trajectory.png"><img alt="Momentum 3D trajectory" src="_images/momentum-3d-trajectory.png" style="width: 80%;"/></a>
</div>
</div>
<div class="section" id="rprop">
<h3><a class="toc-backref" href="#id9">RPROP</a></h3>
<p><a class="reference internal" href="apidocs/neupy.algorithms.gd.momentum.html#neupy.algorithms.gd.momentum.Momentum" title="neupy.algorithms.gd.momentum.Momentum"><span class="xref py py-class docutils literal"><span class="pre">Momentum</span></span></a> makes fewer steps to reach the specified minimum point, but we still can do better. Next algorithm that we are going to check is <a class="reference internal" href="apidocs/neupy.algorithms.gd.rprop.html#neupy.algorithms.gd.rprop.RPROP" title="neupy.algorithms.gd.rprop.RPROP"><span class="xref py py-class docutils literal"><span class="pre">RPROP</span></span></a>.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="_images/rprop-steps.png"><img alt="RPROP steps" src="_images/rprop-steps.png" style="width: 80%;"/></a>
</div>
<p>This improvement looks impressive. Now we are able to see steps without zooming. We got almost the same value as before using just 20 steps, which is approximately 5 times less than <a class="reference internal" href="apidocs/neupy.algorithms.gd.momentum.html#neupy.algorithms.gd.momentum.Momentum" title="neupy.algorithms.gd.momentum.Momentum"><span class="xref py py-class docutils literal"><span class="pre">Momentum</span></span></a> and approximately 40 times less than <a class="reference internal" href="apidocs/neupy.algorithms.gd.base.html#neupy.algorithms.gd.base.GradientDescent" title="neupy.algorithms.gd.base.GradientDescent"><span class="xref py py-class docutils literal"><span class="pre">Gradient</span> <span class="pre">Descent</span></span></a>.</p>
<p>Now we are going to figure out what are the main features of <a class="reference internal" href="apidocs/neupy.algorithms.gd.rprop.html#neupy.algorithms.gd.rprop.RPROP" title="neupy.algorithms.gd.rprop.RPROP"><span class="xref py py-class docutils literal"><span class="pre">RPROP</span></span></a>. We can notice just by looking at the plot above <a class="reference internal" href="apidocs/neupy.algorithms.gd.rprop.html#neupy.algorithms.gd.rprop.RPROP" title="neupy.algorithms.gd.rprop.RPROP"><span class="xref py py-class docutils literal"><span class="pre">RPROP</span></span></a> has a unique step for each weight. There are just two steps for each weight in the input layer for this network. <a class="reference internal" href="apidocs/neupy.algorithms.gd.rprop.html#neupy.algorithms.gd.rprop.RPROP" title="neupy.algorithms.gd.rprop.RPROP"><span class="xref py py-class docutils literal"><span class="pre">RPROP</span></span></a> will increase the step size if gradient don’t change the sign compare to previous epoch, and it will decrease otherwise.</p>
<p>Let’s check a few first weight updates.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="_images/rprop-first-11-steps.png"><img alt="RPROP first 11 steps" src="_images/rprop-first-11-steps.png" style="width: 80%;"/></a>
</div>
<p>From the figure above you can see that first 11 updates have the same direction, so both steps increase their value after each iteration. For the first epoch steps are equal to the same value which we set up at network initialization step. In further iterations they increased by the same constant factor, so after six iteration they got bigger, but they are still equal because they move in one direction all the time.</p>
<p>Now let’s check the next epochs from the figure below. At the 12th epoch gradient changed the direction, but steps are still the same in value. But we can clearly see that gradient changed the sign for the second weight. <a class="reference internal" href="apidocs/neupy.algorithms.gd.rprop.html#neupy.algorithms.gd.rprop.RPROP" title="neupy.algorithms.gd.rprop.RPROP"><span class="xref py py-class docutils literal"><span class="pre">RPROP</span></span></a> updated the step after weight had updated, so the step for the second weight should be smaller for the 13th epoch.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="_images/rprop-11th-to-14th-epochs.png"><img alt="RPROP from 11th to 14th steps" src="_images/rprop-11th-to-14th-epochs.png" style="width: 80%;"/></a>
</div>
<p>Now let’s look at the 13th epoch. It shows us how gradient sign difference at the 12th epoch updated steps. Now the steps are not equal. From the picture above we can see that update on the second weight (y axis) is smaller than on the first weight (x axis).</p>
<p>At the 16th epoch gradient on y axis changed the sign again. Network decreased by constant factor and updated for the second weight at the 17th epoch would be smaller than at the 16th.</p>
<p>To train your intuition you can check the other epochs updates and try to figure out how steps depend on the direction.</p>
</div>
<div class="section" id="irprop">
<h3><a class="toc-backref" href="#id10">iRPROP+</a></h3>
<p><a class="reference internal" href="apidocs/neupy.algorithms.gd.rprop.html#neupy.algorithms.gd.rprop.IRPROPPlus" title="neupy.algorithms.gd.rprop.IRPROPPlus"><span class="xref py py-class docutils literal"><span class="pre">iRPROP+</span></span></a> is almost the same algorithm as <a class="reference internal" href="apidocs/neupy.algorithms.gd.rprop.html#neupy.algorithms.gd.rprop.RPROP" title="neupy.algorithms.gd.rprop.RPROP"><span class="xref py py-class docutils literal"><span class="pre">RPROP</span></span></a> except a small alteration.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="_images/irprop-plus-steps.png"><img alt="iRPROP+ steps" src="_images/irprop-plus-steps.png" style="width: 80%;"/></a>
</div>
<p>As in <a class="reference internal" href="apidocs/neupy.algorithms.gd.rprop.html#neupy.algorithms.gd.rprop.RPROP" title="neupy.algorithms.gd.rprop.RPROP"><span class="xref py py-class docutils literal"><span class="pre">RPROP</span></span></a> algorithm <a class="reference internal" href="apidocs/neupy.algorithms.gd.rprop.html#neupy.algorithms.gd.rprop.IRPROPPlus" title="neupy.algorithms.gd.rprop.IRPROPPlus"><span class="xref py py-class docutils literal"><span class="pre">iRPROP+</span></span></a> make exactly the same first 11 steps.</p>
<p>Now let’s look at the 12th step in the figure below.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="_images/irprop-plus-second-part.png"><img alt="iRPROP+ second part" src="_images/irprop-plus-second-part.png" style="width: 80%;"/></a>
</div>
<p>Second weight (on the y axis) didn’t change the value. At the same epoch <a class="reference internal" href="apidocs/neupy.algorithms.gd.rprop.html#neupy.algorithms.gd.rprop.RPROP" title="neupy.algorithms.gd.rprop.RPROP"><span class="xref py py-class docutils literal"><span class="pre">RPROP</span></span></a> changed the gradient comparing to the previous epoch and just decreased step value after weight update whereas, <a class="reference internal" href="apidocs/neupy.algorithms.gd.rprop.html#neupy.algorithms.gd.rprop.IRPROPPlus" title="neupy.algorithms.gd.rprop.IRPROPPlus"><span class="xref py py-class docutils literal"><span class="pre">iRPROP+</span></span></a> disabled weight update for current epoch (set it up to <cite>0</cite>). And of course it also decreased the step for the second weight. Also you can find that vector for the 12th epoch that looks smaller than for the <a class="reference internal" href="apidocs/neupy.algorithms.gd.rprop.html#neupy.algorithms.gd.rprop.RPROP" title="neupy.algorithms.gd.rprop.RPROP"><span class="xref py py-class docutils literal"><span class="pre">RPROP</span></span></a> algorithm, because we ignored the second weight update. If we check the x axis update size we will find that it has the same value as in <a class="reference internal" href="apidocs/neupy.algorithms.gd.rprop.html#neupy.algorithms.gd.rprop.RPROP" title="neupy.algorithms.gd.rprop.RPROP"><span class="xref py py-class docutils literal"><span class="pre">RPROP</span></span></a> algorithm.</p>
<p>At 13th epoch network again included second weight into the update process, because compared to the previous epoch gradient didn’t change its sign.</p>
<p>The nice thing about this algorithm is that it tries to move in a new direction instead of going back and force and trying to redo updates from the previous epochs.</p>
</div>
<div class="section" id="gradient-descent-and-golden-search">
<h3><a class="toc-backref" href="#id11">Gradient Descent and Golden Search</a></h3>
<p>The last algorithm that I want to show is a <a class="reference internal" href="apidocs/neupy.algorithms.gd.hessian.html#neupy.algorithms.gd.hessian.Hessian" title="neupy.algorithms.gd.hessian.Hessian"><span class="xref py py-class docutils literal"><span class="pre">Newton's</span> <span class="pre">method</span></span></a>. This algorithm is not able to train a network by itself, but it can help other algorithms to do it better. I will use Gradient Descent to show the huge improvement that gives <a class="reference internal" href="apidocs/neupy.algorithms.gd.hessian.html#neupy.algorithms.gd.hessian.Hessian" title="neupy.algorithms.gd.hessian.Hessian"><span class="xref py py-class docutils literal"><span class="pre">Newton's</span> <span class="pre">method</span></span></a>.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="_images/grad-descent-and-gold-search-steps.png"><img alt="Gradient Descent with Golden Search steps" src="_images/grad-descent-and-gold-search-steps.png" style="width: 80%;"/></a>
</div>
<p>It took just two steps to reach the goal. Let’s check the first step. <a class="reference internal" href="apidocs/neupy.algorithms.gd.hessian.html#neupy.algorithms.gd.hessian.Hessian" title="neupy.algorithms.gd.hessian.Hessian"><span class="xref py py-class docutils literal"><span class="pre">Newton's</span> <span class="pre">method</span></span></a> helps to find the best step size that can be in a specified direction. So basically, it just tries multiple combinations until it finds the best one. As you can see from the plot the first step size is almost perfect for the specified direction. If you went farther you would increase the error.</p>
<p>The main disadvantage of <a class="reference internal" href="apidocs/neupy.algorithms.gd.hessian.html#neupy.algorithms.gd.hessian.Hessian" title="neupy.algorithms.gd.hessian.Hessian"><span class="xref py py-class docutils literal"><span class="pre">Newton's</span> <span class="pre">method</span></span></a> is a time complexity. It will take a while to find a good step in specified direction. So for the more complicated networks it can take a lot of time to find a perfect step size.</p>
</div>
</div>
<div class="section" id="bring-them-all-together">
<h2><a class="toc-backref" href="#id12">Bring them all together</a></h2>
<div class="figure align-center">
<a class="reference internal image-reference" href="_images/all-algorithms-steps.png"><img alt="All algorithms steps" src="_images/all-algorithms-steps.png" style="width: 80%;"/></a>
</div>
</div>
<div class="section" id="summary">
<h2><a class="toc-backref" href="#id13">Summary</a></h2>
<table border="1" class="docutils" id="id2">
<caption><span class="caption-text">Summary table</span></caption>
<colgroup>
<col width="50%"/>
<col width="50%"/>
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Algorithm</th>
<th class="head">Number of epochs</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>Gradient Descent</td>
<td>797</td>
</tr>
<tr class="row-odd"><td>Momentum</td>
<td>92</td>
</tr>
<tr class="row-even"><td>RPROP</td>
<td>20</td>
</tr>
<tr class="row-odd"><td>iRPROP+</td>
<td>17</td>
</tr>
<tr class="row-even"><td>Gradient Descent + Golden Search</td>
<td>2</td>
</tr>
</tbody>
</table>
<div class="figure align-center">
<a class="reference internal image-reference" href="_images/compare-number-of-epochs.png"><img alt="Compare number of epochs" src="_images/compare-number-of-epochs.png" style="width: 80%;"/></a>
</div>
<p>There is no perfect algorithm for neural network that can solve all problems. All of them have their own pros and cons. Some of the algorithms can be memory or computationally overwhelming and you have to choose an algorithm depending on the task you want to solve.</p>
<p>All code is available at <a class="reference external" href="https://github.com/itdxer/neupy/blob/master/examples/mlp/gd_algorithms_visualization.py">GitHub</a>. You can play around with the script and set up different learning algorithms and hyperparameters. More algorithms you can find at NeuPy’s <a class="reference internal" href="pages/cheatsheet.html#cheat-sheet"><span class="std std-ref">Cheat sheet</span></a>.</p>
</div>
</div>

        </div>
        <div class="postmeta">
        <div class="author">
            <span>Posted by Yurii Shevchuk</span>
        </div>
        
        <div class="tags">
            <span>
                Tags:
                <a href="tags/supervised.html">supervised</a>, <a href="tags/backpropagation.html">backpropagation</a>, <a href="tags/visualization.html">visualization</a></span>
        </div>
        <div class="comments">
            <a href="http://neupy.com/2015/07/04/visualize_backpropagation_algorithms.html#disqus_thread" data-disqus-identifier="2015/07/04/visualize_backpropagation_algorithms">Leave a comment</a>
        </div></div><div class="archive_link">
        <a href="archive.html"> &mdash; Blog Archive &mdash; </a>
    </div><ul class="related clearfix">
            <li class="left"> &laquo; <a href="page1.html">Newer</a></li>
            <li class="right"></li>
        </ul></article><aside class="sidebar"><section><div class="widget" id="searchbox" role="search">
    <h1><a href="#searchbox">Search</a></h1>
    <form action="search.html" method="get">
          <div class="box">
            <div class="search-input-container">
                <span class="icon"><i class="fa fa-search"></i></span>
                <input type="search" name="q" id="search" placeholder="Search..." />
            </div>
          </div>
    </form>
</div></section><section><div class="widget">
    <h1>Install NeuPy</h1>
    <div class="highligh-bash">
        <div class="highlight">
            <pre>pip install neupy</pre>
        </div>
    </div>
    <p>
        <div>Learn more about NeuPy reading <a href="docs/tutorials.html">tutorials</a> and <a href="pages/documentation.html">documentation</a>.</div>
    </p>
</div></section><section><div class="widget">
    <h1>Issues and feature requests</h1>
    <p>
        If you find a bug or want to suggest a new feature feel free to
        <a href="https://github.com/itdxer/neupy/issues/new">create an issue</a>
        on Github
    </p>
</div></section></aside></div> <!-- #main --></div> <!-- #main-container -->

        <div class="footer-container" role="contentinfo"><footer class="wrapper">&copy; Copyright 2015 - 2019, Yurii Shevchuk. Powered by <a href="http://www.tinkerer.me/">Tinkerer</a> and <a href="http://sphinx.pocoo.org/">Sphinx</a>.</footer></div> <!-- footer-container -->

      </div> <!--! end of #container --><script type="text/javascript">    var disqus_shortname = "neupy";    disqus_count();</script><!--[if lt IE 7 ]>
          <script src="//ajax.googleapis.com/ajax/libs/chrome-frame/1.0.3/CFInstall.min.js"></script>
          <script>window.attachEvent('onload',function(){CFInstall.check({mode:'overlay'})})</script>
        <![endif]-->
    </body>
</html>