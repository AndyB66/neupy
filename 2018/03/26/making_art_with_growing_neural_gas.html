<!DOCTYPE html><!--[if lt IE 7]>      <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js"> <!--<![endif]-->
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <meta name="description" content="NeuPy is a Python library for Artificial Neural Networks. NeuPy supports many different types of Neural Networks from a simple perceptron to deep learning models.">
        <meta name="viewport" content="width=device-width">
        <title>Making Art with Growing Neural Gas &mdash; NeuPy</title>
            <link rel="stylesheet" href="../../../_static/normalize.css" type="text/css">
            <link rel="stylesheet" href="../../../_static/sphinx.css" type="text/css">
            <link rel="stylesheet" href="../../../_static/main.css" type="text/css">
            <link rel="stylesheet" href="../../../_static/flat.css" type="text/css">
            <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
            <link rel="stylesheet" href="../../../_static/font-awesome.min.css" type="text/css">
        <link rel="shortcut icon" href="../../../_static/favicon.ico" /><!-- Load modernizr and JQuery -->
        <script src="../../../_static/vendor/modernizr-2.6.2.min.js"></script>
        <script src="//ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.min.js"></script>
        <script>window.jQuery || document.write('<script src="../../../_static/vendor/jquery-1.8.2.min.js"><\/script>')</script>
        <script src="../../../_static/plugins.js"></script>
        <script src="../../../_static/main.js"></script>
        <link rel="search" title="Search" href="../../../search.html" /><link rel="next" title="Create unique text-style with SOFM" href="../../../2017/12/17/sofm_text_style.html" /><link rel="alternate" type="application/rss+xml" title="RSS" href="../../../rss.html" /><script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../',
        VERSION:     '1.7.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        SOURCELINK_SUFFIX: '.txt',
        HAS_SOURCE:  true
      };
    </script><script type="text/javascript" src="../../../_static/underscore.js"></script><script type="text/javascript" src="../../../_static/doctools.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/javascript" src="../../../_static/disqus.js"></script><script type="text/javascript" src="../../../_static/js/google_analytics.js"></script><script type="text/javascript" src="../../../_static/js/script.js"></script><script type="text/javascript" src="../../../_static/js/copybutton.js"></script>

    <script type="text/javascript">
        $(document).ready(function () {
            // Scroll to content if on small screen
            if (screen.width < 480)
            {
                $(document).scrollTop(document.getElementsByTagName("article")[0].offsetTop - 44);
            }
        });
    </script>
    <style media="screen" type="text/css">
        img { max-width: 800px !important; }
        img[src="../_images/mnist-code-sample-home.png"] { max-width: 600px !important; }
        table { background-color: white; }
        table.docutils.citation  { background-color: inherit; }
        div.highlight { margin-bottom: 20px !important; }

        .limited-width { max-width: 800px; margin: auto; }
        .docutils { width: 100%; }
        a .docutils.literal {
            background-color: inherit !important;
            padding: 0px !important;
            color: #3bbc46 !important;
        }
        .docutils td { padding: 10px; }
        .section { word-wrap:break-word; }
        .descname { font-weight: bold; }
        .highlight-python + .figure { margin-top: 20px; }
        .dataframe { text-align: center !important; width: 100%; margin: 10px 0 10px 0; }
        .dataframe td { padding: 5px; }

        .math .gd { color: #000 !important; } /* Generic.Deleted */
        .math .m { color: #000 !important; } /* Literal.Number */
        .math .s { color: #000 !important; } /* Literal.String */
        .math .mf { color: #000 !important; } /* Literal.Number.Float */
        .math .mh { color: #000 !important; } /* Literal.Number.Hex */
        .math .mi { color: #000 !important; } /* Literal.Number.Integer */
        .math .mo { color: #000 !important; } /* Literal.Number.Oct */
        .math .sc { color: #000 !important; } /* Literal.String.Char */
        .math .s2 { color: #000 !important; } /* Literal.String.Double */
        .math .si { color: #000 !important; } /* Literal.String.Interpol */
        .math .sx { color: #000 !important; } /* Literal.String.Other */
        .math .s1 { color: #000 !important; } /* Literal.String.Single */
        .math .ss { color: #000 !important; } /* Literal.String.Symbol */
        .math .il { color: #000 !important; } /* Literal.Number.Integer.Long */

        /* Background for class and function names */
        dt[id^="neupy."] {
            background-color: #e6edf2;
            border: 1px solid #f8fafb;
            border-radius: 8px;
            padding: 10px 20px;
        }
        div[id^="module-neupy."] h1 {
            display: none;
        }

        /* Search input field */
        .search-input {
            width: 100%;
            padding: 10px;
            display: block;
        }
        .box {
          padding-bottom: 50px;
        }
        .search-input-container {
          width: 100%;
          vertical-align: middle;
          white-space: nowrap;
          position: relative;
        }
        .search-input-container input#search {
          width: 100%;
          height: 50px;
          padding-left: 45px;

          float: left;
          outline: none;
          border: 1px solid #ddd;

          box-sizing: border-box;
          -webkit-box-sizing: border-box;
          -moz-box-sizing: border-box;

          -webkit-border-radius: 5px;
          -moz-border-radius: 5px;
          border-radius: 5px;

          font-family: 'PT Sans', Helvetica, Arial, sans-serif;
          font-size: 12pt;
        }
        .search-input-container .icon {
          position: absolute;
          left: 0;
          top: 50%;
          margin-left: 17px;
          margin-top: 13px;
          z-index: 1;
          color: #93a4ad;
        }

        .docutils.field-list, .docutils.footnote {
            background-color: inherit;
        }
        .large-font {
            font-size: 1.4em !important;
        }
        .right-tag {
            float: right;
            margin-left: 36px !important;
            margin-right: 0px !important;
        }
        .short-description {
            /* We hidde description inside of the article */
            display: none;
        }
        .short-description img {
            max-height: 160px;
            max-width: 40% !important;
            margin-left: 8px;
        }
        #results-list ul.search {
            padding: 0;
            max-width: 900px;
            margin: auto;
        }

        #results-list .short-description {
            /* We show description text in the archive */
            display: block !important;
        }
        #results-list li p {
            margin-bottom: 5px;
            font-size: 0.9em;
        }
        #results-list li {
            background-color: #fff !important;
            margin-bottom: 10px;
            display: block !important;
            padding: 15px;
            border-bottom: 2px solid #ddd;
        }
        #results-list span.tag {
            display: inline-block;
            padding: 3px 4px;
            margin-right: 8px;
            position: relative;
            top: -2px;

            background: #888;
            color: #fff;

            font-size: 0.75em;
            font-weight: 600;
            line-height: 1;
            text-transform: uppercase;

            -webkit-border-radius: 2px;
            -moz-border-radius: 2px;
            border-radius: 2px;
        }
    </style></head>
    <body role="document">
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> or <a href="http://www.google.com/chromeframe/?redirect=true">activate Google Chrome Frame</a> to improve your experience.</p>
        <![endif]-->

      <div id="container"><header role="banner">
        <div>
          <h1><a href="../../../pages/home.html">NeuPy</a></h1>
          <h2>Neural Networks in Python</h2>
        </div>
    </header>
    <nav role="navigation">
      <ul>
        <li class="main-nav">
          <a href="../../../archive.html">Articles</a>
        </li>
        <li class="main-nav">
          <a href="../../../docs/tutorials.html">Tutorials</a>
        </li>
        <li class="main-nav">
          <a href="../../../pages/documentation.html">Documentation</a>
        </li>
        <li class="main-nav">
          <a href="../../../pages/cheatsheet.html">Cheat sheet</a>
        </li>
        <li class="main-nav">
          <a href="../../../pages/model_zoo.html">Model Zoo</a>
        </li>
      </ul>
    </nav>

<div class="main-container" role="main"><div class="main wrapper body clearfix"><article><div class="timestamp postmeta">
            <span>March 26, 2018</span>
        </div>
    <div class="section" id="making-art-with-growing-neural-gas">
<h1>Making Art with Growing Neural Gas</h1>
<div class="figure align-center">
<img alt="Art generated using Growing Neural Gas in NeuPy" src="../../../_images/gng-art-final.png" />
</div>
<div class="short-description">
    <img src="https://raw.githubusercontent.com/itdxer/neupy/master/site/_static/intro/gng-art-intro.png" align="right">
    <p>
    Article shows how to generate unique styles from any image using Growing Neural Gas (GNG). In addition, it explains how this type of neural network works and what problems user might encounter while training it on different images.
    </p>
    <br clear="right">
</div><div class="section" id="introduction">
<h2>Introduction</h2>
<p>I’ve been trying to make that type of art style for quite some time. I applied <a class="reference internal" href="../../../apidocs/neupy.algorithms.competitive.sofm.html#neupy.algorithms.competitive.sofm.SOFM" title="neupy.algorithms.competitive.sofm.SOFM"><span class="xref py py-class docutils literal"><span class="pre">SOFM</span></span></a> to the images, but in most cases it was unsuccessful, mostly because SOFM requires predefined size and structure of the network. With such a requirement it’s difficult to construct tool that converts image to nice art style. Later, I’ve learned more about <a class="reference internal" href="../../../apidocs/neupy.algorithms.competitive.growing_neural_gas.html#neupy.algorithms.competitive.growing_neural_gas.GrowingNeuralGas" title="neupy.algorithms.competitive.growing_neural_gas.GrowingNeuralGas"><span class="xref py py-class docutils literal"><span class="pre">Growing</span> <span class="pre">Neural</span> <span class="pre">Gas</span></span></a> and it helped to resolve main issues with SOFM. In this article, I want to explain how this type of art style can be generated from the image. At the end, I will cover some of the similar, but less successful application with growing neural gas for image processing that I’ve been trying to develop.</p>
</div>
<div class="section" id="image-processing-pipeline">
<h2>Image Processing Pipeline</h2>
<p>Images are not very natural data structure for most of the machine learning algorithms and Growing Neural Gas (GNG) is not an exception. For this reason, we need to represent input image in format that will be understandable for the network. The right format for the GNG would be set of data points. In addition, these data points have to somehow resemble original image. In order to do it, we can binarize our image and after that, every pixel on the image will be either black or white. Each black pixel we can use as a data point and pixel’s position as a feature. In this way, we would be able to extract topological structure of the image and store it as set of data points.</p>
<p>Conversion from the color image to binary image requires three simple image processing steps that we will apply in sequential way.</p>
<ol class="arabic">
<li><p class="first">We need to load our image first</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># skimage version 0.13.1</span>
<span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">data</span><span class="p">,</span> <span class="n">img_as_float</span>

<span class="n">astro</span> <span class="o">=</span> <span class="n">img_as_float</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">astronaut</span><span class="p">())</span>
<span class="n">astro</span> <span class="o">=</span> <span class="n">astro</span><span class="p">[</span><span class="mi">30</span><span class="p">:</span><span class="mi">180</span><span class="p">,</span> <span class="mi">150</span><span class="p">:</span><span class="mi">300</span><span class="p">]</span>
</pre></div>
</div>
<div class="figure align-center">
<img alt="Astronaut image" src="../../../_images/colored-image.png" />
</div>
</li>
<li><p class="first">Convert color image to grayscale</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">color</span>
<span class="n">astro_grey</span> <span class="o">=</span> <span class="n">color</span><span class="o">.</span><span class="n">rgb2grey</span><span class="p">(</span><span class="n">astro</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure align-center">
<img alt="Grayscale image of an astronaut" src="../../../_images/grey-image.png" />
</div>
</li>
<li><p class="first">Apply gaussian blurring. It will allow us to reduce image detalization.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">skimage.filters</span> <span class="kn">import</span> <span class="n">gaussian</span>
<span class="n">blured_astro_grey</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">astro_grey</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure align-center">
<img alt="Blurred and grey scaled astronaut image" src="../../../_images/blured-image.png" />
</div>
</li>
<li><p class="first">Find binarization threshold and convert to the black color every pixel that below this threshold.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">skimage.filters</span> <span class="kn">import</span> <span class="n">threshold_otsu</span>
<span class="c1"># Increase threshold in order to add more</span>
<span class="c1"># details to the binarized image</span>
<span class="n">thresh</span> <span class="o">=</span> <span class="n">threshold_otsu</span><span class="p">(</span><span class="n">astro_grey</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.1</span>
<span class="n">binary_astro</span> <span class="o">=</span> <span class="n">astro_grey</span> <span class="o">&lt;</span> <span class="n">thresh</span>
</pre></div>
</div>
<div class="figure align-center">
<img alt="Binarized astronaut image" src="../../../_images/binary-image.png" />
</div>
<p>In some cases, it might be important to adjust threshold in order to be able to capture all important details. In this example, I added <cite>0.1</cite> to the threshold.</p>
</li>
</ol>
<p>And finally, from the binary image it’s easy to make data points.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">ndenumerate</span><span class="p">(</span><span class="n">binary_astro</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">value</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">y</span><span class="p">,</span> <span class="o">-</span><span class="n">x</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure align-center">
<img alt="Image represented as a set of data points" src="../../../_images/data-points-scatter-plot.png" />
</div>
<p>In the image there are so many data points that it’s not clear if it’s really just a set of data points. But if you zoom in you will see that they really are.</p>
<div class="figure align-center">
<img alt="../../../_images/data-points-eye-scatter-plot.png" src="../../../_images/data-points-eye-scatter-plot.png" />
</div>
<p>We prepared our data and now we need to learn a bit more about GNG network.</p>
</div>
<div class="section" id="growing-neural-gas">
<h2>Growing Neural Gas</h2>
<div class="figure align-center">
<img alt="Growing Neural Gas animation in NeuPy" src="../../../_images/neural-gas-animation.gif" />
</div>
<p>Growing Neural Gas is very simple algorithm and it’s really easy to visualize it. From the animation above you can see how it learns shape of the data. Network, typically, starts with two random points and expands over the space.</p>
<p>In the original paper <a class="footnote-reference" href="#id2" id="id1">[1]</a>, algorithm looks a bit complicated with all variables and terminology, but in reality it’s quite simple. Simplified version of the algorithm might look like this:</p>
<ol class="arabic">
<li><p class="first">Pick one data point at random (red data point).</p>
<div class="figure align-center">
<img alt="Growing Neural Gas - data sampling" src="../../../_images/gng-sampled-point-with-graph.png" />
</div>
<p>Blue region represents large set of data points that occupy space in the form of a unit circle. And green points connected with black lines is our GNG network. Green points are neurons and black line visualize connection between two neurons.</p>
</li>
<li><p class="first">Find two closest neurons (blue data points) to the sampled data point and connect these neurons with an edge.</p>
<div class="figure align-center">
<img alt="Growing Neural Gas - adding new edge" src="../../../_images/gng-added-edge.png" />
</div>
</li>
<li><p class="first">Move closest neuron towards the data point. In addition, you can move neurons, that connected by the edge with closest neuron, towards the same point.</p>
<div class="figure align-center">
<img alt="Growing Neural Gas - update neuron weights (coordinates)" src="../../../_images/gng-updated.png" />
</div>
</li>
<li><p class="first">Each neuron has error that accumulates over time. For every updated neuron we have to increase error. Increase per each neuron equal to the distance (euclidean) from this neuron to the sampled data point. The further the neuron from the data point the larger the error.</p>
</li>
<li><p class="first">Remove edges that haven’t been updated for a while (maybe after 50, 100 or 200 iterations, up to you). In case if there are any neurons that doesn’t have edges then we can remove them too.</p>
</li>
</ol>
<div class="figure align-center">
<img alt="Growing Neural Gas - remove old edges" src="../../../_images/gng-edge-removed.png" />
</div>
<ol class="arabic" start="6">
<li><p class="first">From time to time (maybe every 100 or 200 iterations) we can find neuron that has largest accumulated error. For this neuron we can find it’s neighbour with the highest accumulated error. In the middle way between them we can create new neuron (blue data point) that will be automatically connected to these two neurons and original edge between them will be destroyed.</p>
<div class="figure align-center">
<img alt="Growing Neural Gas - adding new neuron" src="../../../_images/gng-new-neuron-added.png" />
</div>
<p>You can think about this step in the following way. Find neuron that typically makes most errors and add one more neuron near it. This new neuron will help the other neuron to reduce accumulated error. Reduction in error will mean that we better capture structure of our data.</p>
</li>
<li><p class="first">Repeat all the steps many times.</p>
</li>
</ol>
<p>There are a few small extensions to the algorithm has to be added in order to be able to call it Growing Neural Gas, but the most important principles are there.</p>
</div>
<div class="section" id="putting-everything-together">
<h2>Putting Everything Together</h2>
<p>And now we ready to combine power of the image processing pipeline with Growing Neural Gas.</p>
<p>After running for one epoch we can already see some progress. Generated network resembles some distinctive features of our original image. At this point it’s pretty obvious that we don’t have enough neurons in the network in order to capture more details.</p>
<div class="figure align-center">
<img alt="Growing Neural Gas art generation in Neupy - 1st epoch" src="../../../_images/gng-art-epoch-1.png" />
</div>
<p>After 4 more iterations, image looks much closer to the original. You can notice that regions with large amount of data points have been developed properly, but small features like eyes, nose and mouth hasn’t been formed yet. We just have to wait more.</p>
<div class="figure align-center">
<img alt="Growing Neural Gas art generation in Neupy - 5th epoch" src="../../../_images/gng-art-epoch-5.png" />
</div>
<p>After 5 more iterations the eyebrows and eyes have better quality. Even hair has more complex shape.</p>
<div class="figure align-center">
<img alt="Growing Neural Gas art generation in Neupy - 10th epoch" src="../../../_images/gng-art-epoch-10.png" />
</div>
<p>On the 20th iteration network’s training has been stopped since we achieved desired quality of the image.</p>
<div class="figure align-center">
<img alt="Growing Neural Gas art generation in Neupy - 20th epoch" src="../../../_images/gng-art-epoch-20.png" />
</div>
</div>
<div class="section" id="reveal-issues-with-more-examples">
<h2>Reveal Issues with More Examples</h2>
<p>I’ve been doing some experiments with other image as well, and there are a few problems that I’ve encountered.</p>
<p>There are two main components in the art style generation procedure, namely: image processing pipeline and GNG. Let’s look at problem with GNG network. It can be illustrated with the following image.</p>
<div class="figure align-center">
<img alt="Horse image generated using Growing Neural Gas in NeuPy" src="../../../_images/horses.png" />
</div>
<p>If you compare horses you will notice that horse on the right image looks a bit skinnier than the left one. It happened, because neurons in the GNG network are not able to rich edges of the image. After one training pass over the full dataset each neuron is getting pulled from many directions and over the training process it sattels somewhere in the middle, in order to be as close as possible to every sample that pulls it. The more neurons you add to the network the closer it will get to the edge.</p>
<p>Another problem related to the image binarization, the most difficult step in our image processing pipeline. It’s difficult, because each binarization method holds certain set of assumption that can easily fail for different images and there is no general way to do it. You don’t have such a difficulty with the network. It can give you pretty decent results for different images using the same configurations. The only thing that you typically need to control is the maximum number of neurons in the network. The more neuron you allow network to use the better quality of the image it produces.</p>
<p>In this article, I used global binarization method for image processing. This type of binarization generates single threshold for all pixels in the image, which can cause problems. Let’s look at the image below.</p>
<div class="figure align-center">
<img alt="Man with camera in the image generated using Growing Neural Gas in NeuPy" src="../../../_images/camera-man.png" />
</div>
<p>You can see that that there are some building in the background in the left image, but there is none in the right one. It’s hard to capture multiple object using single threshold, especially when they have different shades. For more complex cases you might try to use local thresholding methods.</p>
</div>
<div class="section" id="applying-similar-approach-to-text">
<h2>Applying Similar Approach to Text</h2>
<p>I’ve been also experimenting with text images. In the image below you can see the result.</p>
<div class="figure align-center">
<img alt="Writing text using Growing Neural Gas" src="../../../_images/text-in-page.png" />
</div>
<p>It’s even possible to read text generated by the network. It’s also interesting that with slight modification to the algorithm you can count number of words in the image. We just need to add more blurring and after the training - count number of subgraphs in the network.</p>
<div class="figure align-center">
<img alt="Blured and binarized text image" src="../../../_images/blured-text-binarized.png" />
</div>
<p>After many reruns I typically get number that very close to the right answer (44 words if you count “Region-based” as two words).</p>
<p>I also tried to train GNG network that captures trajectory of the signature. There are a few issues that I couldn’t overcome. In the image below you can clearly see some of these issues.</p>
<div class="figure align-center">
<img alt="Writing signatures using Growing Neural Gas in NeuPy" src="../../../_images/signature.png" />
</div>
<p>You will expect to see a signature as a continuous line and this property is hard to achieve using GNG. In the image above you can see a few places where network tries to cover some regions with small polygons and lines which looks very unnatural.</p>
</div>
<div class="section" id="final-words">
<h2>Final Words</h2>
<p>Beautiful patterns generated from the images, probably, doesn’t reflect the real power of GNG network, but I think that the beauty behind algorithm shouldn’t be underappreciated only because it’s not useful for solving real world problems. There are not many machine learning algorithms that can be used for artistic application and it’s pretty cool when they work even though they weren’t designed for this purpose.</p>
<p>I had a lot of fun trying different ideas and I encourage you to try it as well. If you’re new to machine learning - it’s easy to start with GNG and if you’re an expert, I might try motivating you saying that it’s quite refreshing to work with neural networks that can be easily interpreted and analyzed.</p>
</div>
<div class="section" id="learn-more">
<h2>Learn More</h2>
<p>In case if you want to learn more about algorithms just like GNG then you can read about <a class="reference external" href="http://neupy.com/2017/12/09/sofm_applications.html">SOFM</a>. As I said in the beginning of the article, it doesn’t work as nice as GNG for images, but you can write <a class="reference external" href="http://neupy.com/2017/12/17/sofm_text_style.html">pretty cool text styles</a> or generate <a class="reference external" href="http://neupy.com/2017/12/13/sofm_art.html">beautiful patterns</a>. And, it has some other <a class="reference external" href="http://neupy.com/2017/12/09/sofm_applications.html#applications">interesting applications</a> (even in <a class="reference external" href="http://neupy.com/2017/12/09/sofm_applications.html#visualize-pre-trained-vgg19-network">deep learning</a>).</p>
</div>
<div class="section" id="code">
<h2>Code</h2>
<p>A few notebooks with code are available on github.</p>
<ul class="simple">
<li><a class="reference external" href="https://github.com/itdxer/neupy/blob/master/notebooks/growing-neural-gas/Making%20Art%20with%20Growing%20Neural%20Gas.ipynb">Main notebook</a> that generates all the images using GNG</li>
<li><a class="reference external" href="https://github.com/itdxer/neupy/blob/master/notebooks/growing-neural-gas/Growing%20Neural%20Gas%20animated.ipynb">Growing Neural Gas animation notebook</a></li>
<li>Notebook that generates <a class="reference external" href="https://github.com/itdxer/neupy/blob/master/notebooks/growing-neural-gas/Growing%20Neural%20Gas%20-%20step%20by%20step%20visualizations.ipynb">step by step visualization images for the Growing Neural Gas</a> algorithm</li>
</ul>
</div>
<div class="section" id="references">
<h2>References</h2>
<table class="docutils footnote" frame="void" id="id2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td>A Growing Neural Gas Network Learns Topologies, Bernd Fritzke et al. <a class="reference external" href="https://papers.nips.cc/paper/893-a-growing-neural-gas-network-learns-topologies.pdf">https://papers.nips.cc/paper/893-a-growing-neural-gas-network-learns-topologies.pdf</a></td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id3" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[2]</td><td>Thresholding, tutorial from scikit-image library <a class="reference external" href="http://scikit-image.org/docs/dev/auto_examples/xx_applications/plot_thresholding.html">http://scikit-image.org/docs/dev/auto_examples/xx_applications/plot_thresholding.html</a></td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id4" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[3]</td><td>Thresholding (image processing), wikipedia article <a class="reference external" href="https://en.wikipedia.org/wiki/Thresholding_%28image_processing%29">https://en.wikipedia.org/wiki/Thresholding_%28image_processing%29</a></td></tr>
</tbody>
</table>
</div>
</div>

    <div class="postmeta">
        <div class="author">
            <span>Posted by Yurii Shevchuk</span>
        </div>
        
        <div class="tags">
            <span>
                Tags:
                <a href="../../../tags/image_processing.html">image processing</a>, <a href="../../../tags/unsupervised.html">unsupervised</a>, <a href="../../../tags/art.html">art</a></span>
        </div>
        </div><ul class="related clearfix">
            <li class="left"></li>
            <li class="right"><a href="../../../2017/12/17/sofm_text_style.html">Create unique text-style with SOFM</a> &raquo; </li>
        </ul><div id="disqus_thread"></div><script type="text/javascript">    var disqus_shortname = "neupy";    var disqus_identifier = "2018/03/26/making_art_with_growing_neural_gas";    disqus_thread();</script><noscript>Please enable JavaScript to view the    <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></article><aside class="sidebar"><section><div class="widget" id="searchbox" role="search">
    <h1><a href="#searchbox">Search</a></h1>
    <form action="../../../search.html" method="get">
          <div class="box">
            <div class="search-input-container">
                <span class="icon"><i class="fa fa-search"></i></span>
                <input type="search" name="q" id="search" placeholder="Search..." />
            </div>
          </div>
    </form>
</div></section><section><div class="widget">
    <h1>Install NeuPy</h1>
    <div class="highligh-bash">
        <div class="highlight">
            <pre>pip install neupy</pre>
        </div>
    </div>
    <p>
        <div>Learn more about NeuPy reading <a href="../../../docs/tutorials.html">tutorials</a> and <a href="../../../pages/documentation.html">documentation</a>.</div>
    </p>
</div></section><section><div class="widget">
    <h1>Issues and feature requests</h1>
    <p>
        If you find a bug or want to suggest a new feature feel free to
        <a href="https://github.com/itdxer/neupy/issues/new">create an issue</a>
        on Github
    </p>
</div></section></aside></div> <!-- #main --></div> <!-- #main-container -->

        <div class="footer-container" role="contentinfo"><footer class="wrapper">&copy; Copyright 2015 - 2019, Yurii Shevchuk. Powered by <a href="http://www.tinkerer.me/">Tinkerer</a> and <a href="http://sphinx.pocoo.org/">Sphinx</a>.</footer></div> <!-- footer-container -->

      </div> <!--! end of #container --><!--[if lt IE 7 ]>
          <script src="//ajax.googleapis.com/ajax/libs/chrome-frame/1.0.3/CFInstall.min.js"></script>
          <script>window.attachEvent('onload',function(){CFInstall.check({mode:'overlay'})})</script>
        <![endif]-->
    </body>
</html>