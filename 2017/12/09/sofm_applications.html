<!DOCTYPE html><!--[if lt IE 7]>      <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js"> <!--<![endif]-->
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <meta name="description" content="NeuPy is a Python library for Artificial Neural Networks. NeuPy supports many different types of Neural Networks from a simple perceptron to deep learning models.">
        <meta name="viewport" content="width=device-width">
        <title>Self-Organizing Maps and Applications &mdash; NeuPy</title>
            <link rel="stylesheet" href="../../../_static/normalize.css" type="text/css">
            <link rel="stylesheet" href="../../../_static/sphinx.css" type="text/css">
            <link rel="stylesheet" href="../../../_static/main.css" type="text/css">
            <link rel="stylesheet" href="../../../_static/flat.css" type="text/css">
            <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
            <link rel="stylesheet" href="../../../_static/font-awesome.min.css" type="text/css">
        <link rel="shortcut icon" href="../../../_static/favicon.ico" /><!-- Load modernizr and JQuery -->
        <script src="../../../_static/vendor/modernizr-2.6.2.min.js"></script>
        <script src="//ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.min.js"></script>
        <script>window.jQuery || document.write('<script src="../../../_static/vendor/jquery-1.8.2.min.js"><\/script>')</script>
        <script src="../../../_static/plugins.js"></script>
        <script src="../../../_static/main.js"></script>
        <link rel="search" title="Search" href="../../../search.html" /><link rel="next" title="Hyperparameter optimization for Neural Networks" href="../../../2016/12/17/hyperparameter_optimization_for_neural_networks.html" /><link rel="prev" title="The Art of SOFM" href="../13/sofm_art.html" /><link rel="alternate" type="application/rss+xml" title="RSS" href="../../../rss.html" /><script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../',
        VERSION:     '1.7.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        SOURCELINK_SUFFIX: '.txt',
        HAS_SOURCE:  true
      };
    </script><script type="text/javascript" src="../../../_static/underscore.js"></script><script type="text/javascript" src="../../../_static/doctools.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/javascript" src="../../../_static/disqus.js"></script><script type="text/javascript" src="../../../_static/js/google_analytics.js"></script><script type="text/javascript" src="../../../_static/js/script.js"></script><script type="text/javascript" src="../../../_static/js/copybutton.js"></script>

    <script type="text/javascript">
        $(document).ready(function () {
            // Scroll to content if on small screen
            if (screen.width < 480)
            {
                $(document).scrollTop(document.getElementsByTagName("article")[0].offsetTop - 44);
            }
        });
    </script>
    <style media="screen" type="text/css">
        img { max-width: 800px !important; }
        img[src="../_images/mnist-code-sample-home.png"] { max-width: 600px !important; }
        table { background-color: white; }
        table.docutils.citation  { background-color: inherit; }
        div.highlight { margin-bottom: 20px !important; }

        .limited-width { max-width: 800px; margin: auto; }
        .docutils { width: 100%; }
        a .docutils.literal {
            background-color: inherit !important;
            padding: 0px !important;
            color: #3bbc46 !important;
        }
        .docutils td { padding: 10px; }
        .section { word-wrap:break-word; }
        .descname { font-weight: bold; }
        .highlight-python + .figure { margin-top: 20px; }
        .dataframe { text-align: center !important; width: 100%; margin: 10px 0 10px 0; }
        .dataframe td { padding: 5px; }

        .math .gd { color: #000 !important; } /* Generic.Deleted */
        .math .m { color: #000 !important; } /* Literal.Number */
        .math .s { color: #000 !important; } /* Literal.String */
        .math .mf { color: #000 !important; } /* Literal.Number.Float */
        .math .mh { color: #000 !important; } /* Literal.Number.Hex */
        .math .mi { color: #000 !important; } /* Literal.Number.Integer */
        .math .mo { color: #000 !important; } /* Literal.Number.Oct */
        .math .sc { color: #000 !important; } /* Literal.String.Char */
        .math .s2 { color: #000 !important; } /* Literal.String.Double */
        .math .si { color: #000 !important; } /* Literal.String.Interpol */
        .math .sx { color: #000 !important; } /* Literal.String.Other */
        .math .s1 { color: #000 !important; } /* Literal.String.Single */
        .math .ss { color: #000 !important; } /* Literal.String.Symbol */
        .math .il { color: #000 !important; } /* Literal.Number.Integer.Long */

        /* Background for class and function names */
        dt[id^="neupy."] {
            background-color: #e6edf2;
            border: 1px solid #f8fafb;
            border-radius: 8px;
            padding: 10px 20px;
        }
        div[id^="module-neupy."] h1 {
            display: none;
        }

        /* Search input field */
        .search-input {
            width: 100%;
            padding: 10px;
            display: block;
        }
        .box {
          padding-bottom: 50px;
        }
        .search-input-container {
          width: 100%;
          vertical-align: middle;
          white-space: nowrap;
          position: relative;
        }
        .search-input-container input#search {
          width: 100%;
          height: 50px;
          padding-left: 45px;

          float: left;
          outline: none;
          border: 1px solid #ddd;

          box-sizing: border-box;
          -webkit-box-sizing: border-box;
          -moz-box-sizing: border-box;

          -webkit-border-radius: 5px;
          -moz-border-radius: 5px;
          border-radius: 5px;

          font-family: 'PT Sans', Helvetica, Arial, sans-serif;
          font-size: 12pt;
        }
        .search-input-container .icon {
          position: absolute;
          left: 0;
          top: 50%;
          margin-left: 17px;
          margin-top: 13px;
          z-index: 1;
          color: #93a4ad;
        }

        .docutils.field-list, .docutils.footnote {
            background-color: inherit;
        }
        .large-font {
            font-size: 1.4em !important;
        }
        .right-tag {
            float: right;
            margin-left: 36px !important;
            margin-right: 0px !important;
        }
        .short-description {
            /* We hidde description inside of the article */
            display: none;
        }
        .short-description img {
            max-height: 160px;
            max-width: 40% !important;
            margin-left: 8px;
        }
        #results-list ul.search {
            padding: 0;
            max-width: 900px;
            margin: auto;
        }

        #results-list .short-description {
            /* We show description text in the archive */
            display: block !important;
        }
        #results-list li p {
            margin-bottom: 5px;
            font-size: 0.9em;
        }
        #results-list li {
            background-color: #fff !important;
            margin-bottom: 10px;
            display: block !important;
            padding: 15px;
            border-bottom: 2px solid #ddd;
        }
        #results-list span.tag {
            display: inline-block;
            padding: 3px 4px;
            margin-right: 8px;
            position: relative;
            top: -2px;

            background: #888;
            color: #fff;

            font-size: 0.75em;
            font-weight: 600;
            line-height: 1;
            text-transform: uppercase;

            -webkit-border-radius: 2px;
            -moz-border-radius: 2px;
            border-radius: 2px;
        }
    </style></head>
    <body role="document">
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> or <a href="http://www.google.com/chromeframe/?redirect=true">activate Google Chrome Frame</a> to improve your experience.</p>
        <![endif]-->

      <div id="container"><header role="banner">
        <div>
          <h1><a href="../../../pages/home.html">NeuPy</a></h1>
          <h2>Neural Networks in Python</h2>
        </div>
    </header>
    <nav role="navigation">
      <ul>
        <li class="main-nav">
          <a href="../../../archive.html">Articles</a>
        </li>
        <li class="main-nav">
          <a href="../../../docs/tutorials.html">Tutorials</a>
        </li>
        <li class="main-nav">
          <a href="../../../pages/documentation.html">Documentation</a>
        </li>
        <li class="main-nav">
          <a href="../../../pages/cheatsheet.html">Cheat sheet</a>
        </li>
        <li class="main-nav">
          <a href="../../../pages/model_zoo.html">Model Zoo</a>
        </li>
      </ul>
    </nav>

<div class="main-container" role="main"><div class="main wrapper body clearfix"><article><div class="timestamp postmeta">
            <span>December 09, 2017</span>
        </div>
    <div class="section" id="self-organizing-maps-and-applications">
<span id="sofm-applications"></span><h1><a class="toc-backref" href="#id1">Self-Organizing Maps and Applications</a></h1>
<div class="short-description">
    <img src="https://raw.githubusercontent.com/itdxer/neupy/master/site/_static/intro/sofm-dnn-intro.png" align="right">
    <p>
    Self-Organizing Feature Map (SOFM or SOM) is a simple algorithm for unsupervised learning. It can be applied to solve vide variety of problems. It quite good at learning topological structure of the data and it can be used for visualizing deep neural networks.
    </p>
    <p>
    This article explains how SOFM works and shows different applications where it can be used.
    </p>
    <br clear="right">
</div><div class="contents topic" id="contents">
<p class="topic-title first">Contents</p>
<ul class="simple">
<li><a class="reference internal" href="#self-organizing-maps-and-applications" id="id1">Self-Organizing Maps and Applications</a><ul>
<li><a class="reference internal" href="#introduction" id="id2">Introduction</a></li>
<li><a class="reference internal" href="#intuition-behind-sofm" id="id3">Intuition behind SOFM</a></li>
<li><a class="reference internal" href="#applications" id="id4">Applications</a><ul>
<li><a class="reference internal" href="#clustering" id="id5">Clustering</a></li>
<li><a class="reference internal" href="#space-approximation" id="id6">Space approximation</a></li>
<li><a class="reference internal" href="#high-dimensional-data-visualization" id="id7">High-dimensional data visualization</a></li>
</ul>
</li>
<li><a class="reference internal" href="#visualize-pre-trained-vgg19-network" id="id8">Visualize pre-trained VGG19 network</a></li>
<li><a class="reference internal" href="#summary" id="id9">Summary</a></li>
<li><a class="reference internal" href="#code" id="id10">Code</a></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="introduction">
<h2><a class="toc-backref" href="#id2">Introduction</a></h2>
<p>I was fascinated for a while with SOFM algorithm and that’s why I decided to write this article. The reason why I like it so much because it’s pretty simple and powerful approach that can be applied to solve different problems.</p>
<p>I believe that it’s important to understand the idea behind any algorithm even if you don’t know how to build it. For this reason, I won’t give detailed explanation on how to build your own SOFM network. Instead, I will focus on the intuition behind this algorithm and applications where you can use it. If you want to build it yourself I recommend you to read <a class="reference external" href="http://hagan.okstate.edu/NNDesign.pdf">Neural Network Design</a> book.</p>
</div>
<div class="section" id="intuition-behind-sofm">
<h2><a class="toc-backref" href="#id3">Intuition behind SOFM</a></h2>
<p>As in case of any neural network algorithms the main building blocks for SOFM are <strong>neurons</strong>. Each neuron typically connected to some other neurons, but number of this connections is small. Each neuron connected just to a few other neurons that we call <strong>close neighbors</strong>. There are many ways to arrange these connections, but the most common one is to arrange them into two-dimensional grid.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../../../_images/sofm-grid.png"><img alt="SOFM grid" src="../../../_images/sofm-grid.png" style="width: 50%;" /></a>
</div>
<p>Each blue dot in the image is neuron and line between two neurons means that they are connected. We call this arrangement of neurons <em>grid</em>.</p>
<p>Each neuron in the grid has two properties: position and connections to other neurons. We define connections before we start network training and position is the only thing that changes during the training. There are many ways to initialize position for the neurons, but the easiest one is just to do it randomly. After this initialization grid won’t look as nice as it looks on the image above, but with more training iteration problem can be solved.</p>
<p>Let’s talk about training. In each training iteration we introduce some data point and we try to find neuron that closest to this point. Neuron that closest to this point we call <strong>neuron winner</strong>. But, instead of updating position of this neuron we find its <strong>neighbors</strong>. Note, that it’s not the same as closest neighbors. Before training we specify special parameter known as <strong>learning radius</strong>. It defines the radius within which we consider other neuron as a neighbors. On the image below you can see the same grid as before with neuron in center that we marked as a winner. You can see in the pictures that larger radius includes more neurons.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../../../_images/sofm-learning-radius-comparison.png"><img alt="Compare SOFM learning radius size" src="../../../_images/sofm-learning-radius-comparison.png" style="width: 100%;" /></a>
</div>
<p>And at the end of the iteration we update our neuron winner and its neighbors positions. We change their position by pushing closer to the data point that we used to find neuron winner. We “push” winner neuron much closer to the data point compared to the neighbor neurons. In fact, the further the neighbors the less “push” it get’s towards the data point. You can see how we update neurons on the image below with different learning radius parameters.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../../../_images/sofm-training-learning-radius-comparison.png"><img alt="Compare SOFM learning radius size" src="../../../_images/sofm-training-learning-radius-comparison.png" style="width: 100%;" /></a>
</div>
<p>You probably noticed that idea is very similar to k-means algorithm, but what makes it really special is the existing relations with other neurons.</p>
<p>It’s easy to compare this algorithm to real world. Imagine that you try to put large tablecloth on the large table. First you put it so that it will partially cover table. Then you will go around and pull different sides of the tablecloth until you cover the table. But when you pull one side, another part of the tablecloth starts moving to the direction in which you pull it, just like it happens during the training in SOFM.</p>
</div>
<div class="section" id="applications">
<h2><a class="toc-backref" href="#id4">Applications</a></h2>
<p>Surprisingly, this simple idea has a variety of applications. In this part of the article, I’ll cover a few most common applications.</p>
<div class="section" id="clustering">
<h3><a class="toc-backref" href="#id5">Clustering</a></h3>
<p>Clustering is probably the most trivial application where you can use SOFM. In case of clustering, we treat every neuron as a centre of separate cluster. One of the problems is that during the training procedure when we pull one neuron closer to one of the cluster we will be forced to pull its neighbors as well. In order to avoid this issue, we need to break relations between neighbors, so that any update will not have influence on other neurons. If we set up this value as 0 it will mean that neuron winner doesn’t have any relations with other neurons which is exactly what we need for clustering.</p>
<p>In the image below you can see visualized two features from the iris dataset and there are three SOFM neurons colored in grey. As you can see it managed to find pretty good centers of the clusters.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ python sofm_iris_clustering.py
</pre></div>
</div>
<br><div class="figure align-center">
<a class="reference internal image-reference" href="../../../_images/sofm-iris-clustering.png"><img alt="Clustering iris dataset using SOFM" src="../../../_images/sofm-iris-clustering.png" style="width: 100%;" /></a>
</div>
<p>Clustering application is the useful one, but it’s not very special one. If you try to run k-mean algorithm on the same dataset that I used in this example you should be able to get roughly the same result. I don’t see any advantages for SOFM with learning radius equal to 0 against k-means. I like to think about SOFM clustering application more like a debugging. When you are trying to find where your code breaks you can disable some parts of it and try to see if the specific function breaks. With SOFM we are disabling some parts in order to see how other things will behave without it.</p>
<p>What would happen if we increase number of clusters? Let’s increase number of clusters from 3 to 20 and run clustering on the same data.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../../../_images/sofm-20-clusters.png"><img alt="Clustering iris dataset using SOFM with 20 clusters" src="../../../_images/sofm-20-clusters.png" style="width: 100%;" /></a>
</div>
<p>Neurons just spread out all over the data trying to cover it. Just in this case, since we have lots of clusters each one will cover smaller portion of the data. We can call it a <strong>micro-clustering</strong>.</p>
</div>
<div class="section" id="space-approximation">
<h3><a class="toc-backref" href="#id6">Space approximation</a></h3>
<p>In the previous example, we tried to do a <strong>space approximation</strong>. Space approximation is similar to clustering, but the goal is here to find the minimum number of points that cover as much data as possible. Since it’s similar to clustering we can use SOFM here as well. But as we saw in the previous example data points wasn’t using space efficiently and some points were very close to each other and some are further. Now the problem is that clusters don’t know about existence of other clusters and they behave independently. To have more cooperative behavior between clusters we can enable learning radius in SOFM. Let’s try different example. I generated two-dimensional dataset in the shape of the moon that we will try to approximate using SOFM. First, let’s try to do it without increasing learning radius and applying the same micro-clustering technique as before.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../../../_images/sofm-moon-topology-0-radius.png"><img alt="Learning moon topology with clustering" src="../../../_images/sofm-moon-topology-0-radius.png" style="width: 100%;" /></a>
</div>
<p>As you can see we have the same issue as we had with iris dataset. On the left side there are a few cluster centers that very close to each other and on the right side they are further apart. Now, let’s try to set up learning radius equal to 2 and let’s look what will happen.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ python sofm_moon_topology.py
</pre></div>
</div>
<br><div class="figure align-center">
<a class="reference internal image-reference" href="../../../_images/sofm-moon-topology.png"><img alt="Learning moon topology with clustering and learning radius" src="../../../_images/sofm-moon-topology.png" style="width: 100%;" /></a>
</div>
<p>You can see that cluster centers are more efficiently distributed along the moon-shaped cluster. Even if we remove data points from the plot the center cluster will give us good understanding about the shape of our original data.</p>
<p>You might ask, what is the use of this application? One of the things that you can do is to use this approach in order to minimize the size of your data sample. The idea is that since feature map spreads out all over the space you can generate smaller dataset that will keep useful properties of the main one. It can be not only useful for training sample minimization, but also for other applications. For instance, in case if you have lots of unlabelled data and labelling can get expensive, you can use the same technique to find smaller sub-sample of the main dataset and label only this subset instead of the random sample.</p>
<p>We can use more than one-dimensional grids in SOFM in order to be able to capture more complicated patterns. In the following example, you can see SOFM with two-dimensional feature map that approximates roughly 8,000 data points using only 100 features.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ python sofm_compare_grid_types.py
</pre></div>
</div>
<br><div class="figure align-center">
<a class="reference internal image-reference" href="../../../_images/sofm-grid-types.png"><img alt="Compare hexagonal and rectangular grid types in SOFM" src="../../../_images/sofm-grid-types.png" style="width: 100%;" /></a>
</div>
<p>The same property of space approximation can be extended to the high-dimensional datasets and used for visualizations.</p>
</div>
<div class="section" id="high-dimensional-data-visualization">
<h3><a class="toc-backref" href="#id7">High-dimensional data visualization</a></h3>
<p>We used SOFM with two-dimensional feature map in order to catch dimensional properties of the datasets with only two features. If we increase number of dimensions to three it still would be possible to visualize the result, but in four dimensions it will become a bit trickier.</p>
<p>If we use two-dimensional grid and train SOFM over the high-dimensional data then we can encode network as a heat map where each neuron in the network will be represented by the average distance to its neighbors.</p>
<p>As the example, let’s take a look at the <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html">breast cancer dataset</a> available in the <a class="reference external" href="http://scikit-learn.org">scikit-learn library</a>. This dataset has 30 features and two classes.</p>
<p>Let’s look what we can get if we apply described method on the 30-dimensional data.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ python sofm_heatmap_visualization.py
</pre></div>
</div>
<br><div class="figure align-center">
<a class="reference internal image-reference" href="../../../_images/sofm-heatmap.png"><img alt="Embedded 30-dimensional dataset using SOFM" src="../../../_images/sofm-heatmap.png" style="width: 100%;" /></a>
</div>
<p>For this example, I used SOFM with 20x20 feature map. Which basically means that we have 400 micro-clusters. Most of the micro-clusters has either blue squares or red circles and just a few of them has both or none of the classes.</p>
<p>You can see how micro-clusters with blue squares are tended to be close to each other, and the same true for red circles. In fact, we can even draw simple bound that will separate two different classes from each other. Along this bound we can see some cases where micro-cluster has red and blue classes which means that at some places these samples sit very tight. In other cases, like in the left down corner, we can see parts that do not belong to any of the classes which means that there is a gap between data points.</p>
<p>You can also notice that each cell in the heat map has different color. From the colorbar, we can see that black color encodes small numbers and white color encodes large numbers. Each cell has a number associated with it that defines average distance to neighbor clusters. The white color means that cluster is far away from it’s neighbors. Group of the red circles on the right side of the plot has white color, which means that this group is far from the main cluster.</p>
<p>One problem is that color depends on the average distance which can be misleading in some cases. We can build a bit different visualization that will encode distance between two separate micro-clusters as a single value.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ python sofm_heatmap_visualization.py --expanded-heatmap
</pre></div>
</div>
<br><div class="figure align-center">
<a class="reference internal image-reference" href="../../../_images/sofm-heatmap-expanded.png"><img alt="Embedded 30-dimensional dataset using SOFM" src="../../../_images/sofm-heatmap-expanded.png" style="width: 100%;" /></a>
</div>
<p>Now between every feature and its neighbor there is an extra square. As in the previous example each square encodes distance between two neighboring features. We do not consider two features in the map as neighbors in case if they connected diagonally. That’s why all diagonal squares between two micro-clusters color in black. Diagonals are a bit more difficult to encode, because in this case we have two different cases. In order to visualize it we can also take an average of these distances.</p>
<p>More interesting way to make this type of visualization can be with the use of images. In previous case, we use markers to encode two different classes. With images, we can use them directly as the way to represent the cluster. Let’s try to apply this idea on small dataset with images of digits from 0 to 9.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ python sofm_digits.py
</pre></div>
</div>
<br><div class="figure align-center">
<a class="reference internal image-reference" href="../../../_images/sofm-digits.png"><img alt="Embeding digit images into two dimensional space using SOFM" src="../../../_images/sofm-digits.png" style="width: 100%;" /></a>
</div>
</div>
</div>
<div class="section" id="visualize-pre-trained-vgg19-network">
<h2><a class="toc-backref" href="#id8">Visualize pre-trained VGG19 network</a></h2>
<p>Using the same techniques, we can look inside the deep neural networks. In this section, I will be looking on the pre-trained VGG19 network using ImageNet data. Only in this case, I decided to make it a bit more challenging. Instead of using data from ImageNet I decided to pick 9 classes of different animal species from <a class="reference external" href="http://www.vision.caltech.edu/Image_Datasets/Caltech101/">Caltech 101 dataset</a>. The interesting part is that there are a few species that are not in the ImageNet.</p>
<p>The goal for this visualization is not only to see how the VGG19 network will separate different classes, but also to see if it would be able to extract some special features of the new classes that it hasn’t seen before. This information can be useful for the Transfer Learning, because from the visualization we should be able to see if network can separate unknown class from the other. If it will then it means there is no need to re-train all layers below the one which we are visualizing.</p>
<p>From the Caltech 101 dataset I picked the following classes:</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../../../_images/caltech-101-animal-classes.png"><img alt="9 animal classes from the Caltech 101 dataset" src="../../../_images/caltech-101-animal-classes.png" style="width: 100%;" /></a>
</div>
<p>There are a few classes that hasn’t been used in ImageNet, namely Okapi, Wild cat and Platypus.</p>
<p>Data was prepared in the same way as it was done for the VGG19 during training on ImageNet data. I first removed final layer from the network. Now output for each image should be 4096-dimensional vector. Because of the large dimensional size, I used cosine similarity in order to find closest SOFM neurons (instead of euclidian which we used in all previous examples).</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../../../_images/vgg19-sofm-dense-2-20x20.png"><img alt="Visualized feature space using pre-trained VGG19 and 9 animal classes from the Caltech 101 dataset" src="../../../_images/vgg19-sofm-dense-2-20x20.png" style="width: 100%;" /></a>
</div>
<p>Even without getting into the details it’s easy to see that SOFM produces pretty meaningful visualization. Similar species are close to each other in the visualization which means that the main properties was captured correctly.</p>
<p>We can also visualize output from the last layer. From the network, we only need to remove final Softmax layer in order to get raw activation values. Using this values, we can also visualize our data.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../../../_images/vgg19-sofm.png"><img alt="Visualized feature space using pre-trained VGG19 and 9 animal classes from the Caltech 101 dataset" src="../../../_images/vgg19-sofm.png" style="width: 100%;" /></a>
</div>
<p>SOFM managed to identify high-dimensional structure pretty good. There are many interesting things that we can gain from this image. For instance, beaver and platypus share similar features. Since platypus wasn’t a part of the ImageNet dataset it is a reasonable mistake for the network to mix these species.</p>
<p>You probably noticed that there are many black squares in the image. Each square represents a gap between two micro-clusters. You can see how images of separate species are separated from other species with these gaps.</p>
<p>You can also see that network learned to classify rotated and scaled images very similarly which tells us that it is robust against small transformations applied to the image. In the image below, we can see a few examples.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../../../_images/vgg19-sofm-similar-examples.png"><img alt="Similar images tend to be closer to each other in high-dimensional space" src="../../../_images/vgg19-sofm-similar-examples.png" style="width: 100%;" /></a>
</div>
<p>There are also some things that shows us problems with VGG19 network.. For instance, look at the image of llama that really close to the cheetah’s images.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../../../_images/vgg19-sofm-llama-similar-to-cheetah.png"><img alt="Llama close to cheetah in high dimensional space." src="../../../_images/vgg19-sofm-llama-similar-to-cheetah.png" style="width: 100%;" /></a>
</div>
<p>This image looks out of place. We can check top 5 classes based on the probability that network gives to this image.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../../../_images/llama-with-spots.jpg"><img alt="Llama with spots" src="../../../_images/llama-with-spots.jpg" style="width: 30%;" /></a>
</div>
<br><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">llama</span>                                    <span class="p">:</span> <span class="mf">31.18</span><span class="o">%</span>
<span class="n">cheetah</span><span class="p">,</span> <span class="n">chetah</span><span class="p">,</span> <span class="n">Acinonyx</span> <span class="n">jubatus</span>        <span class="p">:</span> <span class="mf">22.62</span><span class="o">%</span>
<span class="n">tiger</span><span class="p">,</span> <span class="n">Panthera</span> <span class="n">tigris</span>                   <span class="p">:</span> <span class="mf">8.20</span><span class="o">%</span>
<span class="n">lynx</span><span class="p">,</span> <span class="n">catamount</span>                          <span class="p">:</span> <span class="mf">7.34</span><span class="o">%</span>
<span class="n">snow</span> <span class="n">leopard</span><span class="p">,</span> <span class="n">ounce</span><span class="p">,</span> <span class="n">Panthera</span> <span class="n">uncia</span>      <span class="p">:</span> <span class="mf">5.91</span><span class="o">%</span>
</pre></div>
</div>
<p>Prediction is correct, but look at the second choice. Percentage that it might be a cheetah is also pretty high. Even though cheetah and llama species are not very similar to each other, network still thinks that it can be a cheetah. The most obvious explanation of this phenomena is that llama in the image covered with spots all over the body which is a typical feature for cheetah. This example shows how easily we can fool the network.</p>
</div>
<div class="section" id="summary">
<h2><a class="toc-backref" href="#id9">Summary</a></h2>
<p>In the article, I mentioned a few applications where SOFM can be used, but it’s not the full list. It can be also used for other applications like robotics or even for creating some beautiful pictures. It is fascinating how such a simple set of rules can be applied in order to solve very different problems.</p>
<p>Despite all the positive things that can be said about SOFM there are some problems that you encounter.</p>
<ul class="simple">
<li>There are many hyperparameters and selecting the right set of parameter can be tricky.</li>
<li>SOFM doesn’t cover borders of the dataspace which means that area, volume or hypervolume of the data will be smaller than it is in real life. You can see it from the picture where we approximate circles.</li>
</ul>
<div class="figure align-center">
<a class="reference internal image-reference" href="../../../_images/sofm-grid-types.png"><img alt="Compare hexagonal and rectangular grid types in SOFM" src="../../../_images/sofm-grid-types.png" style="width: 100%;" /></a>
</div>
<p>It also means that if you need to pick information about outliers from your data - SOFM will probably miss it.</p>
<ul class="simple">
<li>Not every space approximates with SOFM. There can be some cases where SOFM fits data poorly which sometimes difficult to see.</li>
</ul>
</div>
<div class="section" id="code">
<h2><a class="toc-backref" href="#id10">Code</a></h2>
<p>iPython notebook with code that explores VGG19 using SOFM available on <a class="reference external" href="https://github.com/itdxer/neupy/blob/master/notebooks/Looking%20inside%20of%20the%20VGG19%20using%20SOFM.ipynb">github</a>. NeuPy has Python scripts that can help you to start work with SOFM or show you how you can use SOFM for different applications.</p>
<ul class="simple">
<li><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/examples/competitive/sofm_basic.py">Simple SOFM example</a></li>
<li><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/examples/competitive/sofm_iris_clustering.py">Clustering iris dataset using SOFM</a></li>
<li><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/examples/competitive/sofm_moon_topology.py">Learning half-circle topology with SOFM</a></li>
<li><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/examples/competitive/sofm_compare_grid_types.py">Compare feature grid types for SOFM</a></li>
<li><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/examples/competitive/sofm_compare_weight_init.py">Compare weight initialization methods for SOFM</a></li>
<li><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/examples/competitive/sofm_digits.py">Visualize digit images in 2D space with SOFM</a></li>
<li><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/examples/competitive/sofm_heatmap_visualization.py">Embedding 30-dimensional dataset into 2D and building heatmap visualization for SOFM</a></li>
</ul>
</div>
</div>

    <div class="postmeta">
        <div class="author">
            <span>Posted by Yurii Shevchuk</span>
        </div>
        
        <div class="tags">
            <span>
                Tags:
                <a href="../../../tags/sofm.html">sofm</a>, <a href="../../../tags/deep_learning.html">deep learning</a>, <a href="../../../tags/image_recognition.html">image recognition</a>, <a href="../../../tags/unsupervised.html">unsupervised</a>, <a href="../../../tags/visualization.html">visualization</a>, <a href="../../../tags/clustering.html">clustering</a></span>
        </div>
        </div><ul class="related clearfix">
            <li class="left"> &laquo; <a href="../13/sofm_art.html">The Art of SOFM</a></li>
            <li class="right"><a href="../../../2016/12/17/hyperparameter_optimization_for_neural_networks.html">Hyperparameter optimization for Neural Networks</a> &raquo; </li>
        </ul><div id="disqus_thread"></div><script type="text/javascript">    var disqus_shortname = "neupy";    var disqus_identifier = "2017/12/09/sofm_applications";    disqus_thread();</script><noscript>Please enable JavaScript to view the    <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></article><aside class="sidebar"><section><div class="widget" id="searchbox" role="search">
    <h1><a href="#searchbox">Search</a></h1>
    <form action="../../../search.html" method="get">
          <div class="box">
            <div class="search-input-container">
                <span class="icon"><i class="fa fa-search"></i></span>
                <input type="search" name="q" id="search" placeholder="Search..." />
            </div>
          </div>
    </form>
</div></section><section><div class="widget">
    <h1>Install NeuPy</h1>
    <div class="highligh-bash">
        <div class="highlight">
            <pre>pip install neupy</pre>
        </div>
    </div>
    <p>
        <div>Learn more about NeuPy reading <a href="../../../docs/tutorials.html">tutorials</a> and <a href="../../../pages/documentation.html">documentation</a>.</div>
    </p>
</div></section><section><div class="widget">
    <h1>Issues and feature requests</h1>
    <p>
        If you find a bug or want to suggest a new feature feel free to
        <a href="https://github.com/itdxer/neupy/issues/new">create an issue</a>
        on Github
    </p>
</div></section></aside></div> <!-- #main --></div> <!-- #main-container -->

        <div class="footer-container" role="contentinfo"><footer class="wrapper">&copy; Copyright 2015 - 2019, Yurii Shevchuk. Powered by <a href="http://www.tinkerer.me/">Tinkerer</a> and <a href="http://sphinx.pocoo.org/">Sphinx</a>.</footer></div> <!-- footer-container -->

      </div> <!--! end of #container --><!--[if lt IE 7 ]>
          <script src="//ajax.googleapis.com/ajax/libs/chrome-frame/1.0.3/CFInstall.min.js"></script>
          <script>window.attachEvent('onload',function(){CFInstall.check({mode:'overlay'})})</script>
        <![endif]-->
    </body>
</html>